[{"content":"💡 不可以对查询参数加解密\n💡 不会修改原对象数据\n💡 对于手写sql需要特殊指定\n💡 对于非sql的CRUD可自动加解密\n1. 非sql查询 — 数据库实体类 1 2 3 4 @TableName(value = \u0026#34;t_user_auth\u0026#34;, autoResultMap = true) @TableField(typeHandler = CryptHandler.class) private String cardNo; 2. 非sql查询 — typrHandler实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Slf4j public class CryptHandler extends BaseTypeHandler\u0026lt;String\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { log.warn(parameter); ps.setString(i, \u0026#34;DESUtil.encrypt(parameter)\u0026#34;); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { String string = rs.getString(columnName); log.warn(string); return \u0026#34;DESUtil.decrypt(string)\u0026#34;; } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { String string = rs.getString(columnIndex); log.warn(string); return \u0026#34;DESUtil.decrypt(string)\u0026#34;; } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { String string = cs.getString(columnIndex); log.warn(string); return \u0026#34;DESUtil.decrypt(string)\u0026#34;; } } 3. sql查询 — 其他复杂查询 1 2 3 4 \u0026lt;resultMap id=\u0026#34;filterListMap\u0026#34; type=\u0026#34;com.somenet.response.patient.MPatientFilterResponse\u0026#34;\u0026gt; \u0026lt;result column=\u0026#34;card_no\u0026#34; property=\u0026#34;cardNo\u0026#34; typeHandler=\u0026#34;com.somenet.handler.crypt.CryptHandler\u0026#34; /\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;filterList\u0026#34; resultMap=\u0026#34;filterListMap\u0026#34; \u0026gt; ","permalink":"https://habyss.github.io/posts/tech/mybatis_plus_typehandler/","summary":"💡 不可以对查询参数加解密 💡 不会修改原对象数据 💡 对于手写sql需要特殊指定 💡 对于非sql的CRUD可自动加解密 1. 非sql查询 — 数据库实体类 1 2","title":"mybatis-plus typeHandler 加解密简单实现"},{"content":"一、超时优化 OpenFeign 底层内置了 Ribbon 框架，并且使用了 Ribbon 的请求连接超时时间和请求处理超时时间作为其超时时间，而 Ribbon 默认的请求连接超时时间和请求处理超时时间都是 1s, 当我们使用 OpenFeign 调用了服务接口超过 1s，就会出现错误.\n因为 1s 确实太短了，因此我们需要手动设置 OpenFeign 的超时时间以保证它能正确的处理业务。OpenFeign 的超时时间有以下两种更改方法：\n通过修改 Ribbon 的超时时间，被动的修改 OpenFeign 的超时时间。 直接修改 OpenFeign 的超时时间(推荐使用)。 1、设置Ribbon超时时间(未验证) 在项目配置文件 application.yml 中添加以下配置：\n1 2 3 ribbon: ReadTimeout: 5000 # 请求连接的超时时间 ConnectionTimeout: 10000 # 请求处理的超时时间 2、设置OpenFeign超时时间 在项目配置文件 application.yml 中添加以下配置：\n1 2 3 4 5 6 feign: client: config: default: connect-timeout: 2000 read-timeout: 5000 推荐使用此方式来设置 OpenFeign 的超时时间，因为这样的配置语义更明确。\n二、请求连接优化 OpenFeign 底层通信组件默认使用 JDK 自带的 URLConnection 对象进行 HTTP 请求的，因为没有使用连接池，所以性能不是很好。我们可以将 OpenFeign 的通讯组件，手动替换成像 Apache HttpClient 或 OKHttp 这样的专用通信组件，这些的专用通信组件自带连接池可以更好地对 HTTP 连接对象进行重用与管理，同时也能大大的提升 HTTP 请求的效率。接下来以 Apache HttpClient 为例，演示一下专用通讯组件的使用。\n1、引入Apache HttpClient依赖 在项目的依赖管理文件 pom.xml 中添加以下配置：\n1 2 3 4 5 6 7 8 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2、开启Apache HttpClient使用 启动 Apache HttpClient 组件，在项目配置文件 application.yml 中添加以下配置,\n1 2 3 feign: httpclient: enabled: true 三、数据压缩 OpenFeign 默认不会开启数据压缩功能，但我们可以手动的开启它的 Gzip 压缩功能，这样可以极大的提高宽带利用率和加速数据的传输速度，在项目配置文件 application.yml 中添加以下配置：\n1 2 3 4 5 6 7 8 9 feign: compression: request: enabled: true # 默认就是这些类型 # mime-types: text/xml, application/xml, application/json min-request-size: 1024 response: enabled: true PS：如果服务消费端的 CPU 资源比较紧张的话，建议不要开启数据的压缩功能，因为数据压缩和解压都需要消耗 CPU 的资源，这样反而会给 CPU 增加了额外的负担，也会导致系统性能降低。\n四、负载均衡优化 OpenFeign 底层使用的是 Ribbon 做负载均衡的，查看源码我们可以看到它默认的负载均衡策略是轮询策略\n然而除了轮询策略之外，我们还有其他 6 种内置的负载均衡策略可以选择，这些负载均衡策略如下：\n**权重策略：**WeightedResponseTimeRule，根据每个服务提供者的响应时间分配一个权重，响应时间越长，权重越小，被选中的可能性也就越低。它的实现原理是，刚开始使用轮询策略并开启一个计时器，每一段时间收集一次所有服务提供者的平均响应时间，然后再给每个服务提供者附上一个权重，权重越高被选中的概率也越大。 **最小连接数策略：**BestAvailableRule，也叫最小并发数策略，它是遍历服务提供者列表，选取连接数最小的⼀个服务实例。如果有相同的最小连接数，那么会调用轮询策略进行选取。 **区域敏感策略：**ZoneAvoidanceRule，根据服务所在区域(zone)的性能和服务的可用性来选择服务实例，在没有区域的环境下，该策略和轮询策略类似。 **可用敏感性策略：**AvailabilityFilteringRule，先过滤掉非健康的服务实例，然后再选择连接数较小的服务实例。 **随机策略：**RandomRule，从服务提供者的列表中随机选择一个服务实例。 **重试策略：**RetryRule，按照轮询策略来获取服务，如果获取的服务实例为 null 或已经失效，则在指定的时间之内不断地进行重试来获取服务，如果超过指定时间依然没获取到服务实例则返回 null。 出于性能方面的考虑，我们可以选择用权重策略或区域敏感策略来替代轮询策略，因为这样的执行效率最高。\n五、日志级别优化 OpenFeign 提供了日志增强功能，它的日志级别有以下几个：\n**NONE：**默认的，不显示任何日志。 **BASIC：**仅记录请求方法、URL、响应状态码及执行时间。 **HEADERS：**除了 BASIC 中定义的信息之外，还有请求和响应的头信息。 **FULL：**除了 HEADERS 中定义的信息之外，还有请求和响应的正文及元数据。 我们可以通过配置文件来设置日志级别，配置信息如下：\n1 2 3 4 5 6 7 8 9 10 @Configuration public class OpenfeignConfig { @Bean Logger.Level feignLoggerLevel(){ return Logger.Level.FULL;//FULL是详细日志 } } logging: level: cn.xxx.service: debug 其中 cn.xxx.service 为 OpenFeign 接口所在的包名。虽然 OpenFeign 默认是不输出任何日志，但在开发阶段可能会被修改，因此在生产环境中，我们应仔细检查并设置合理的日志级别，以提高 OpenFeign 的运行效率。\n总结 OpenFeign 是 Spring 官方推出的一种声明式服务调用和负载均衡组件，在生产环境中我们可以通过以下配置来优化 OpenFeign 的运行：\n修改 OpenFeign 的超时时间，让 OpenFeign 能够正确的处理业务。 通过配置专用的通信组件 Apache HttpClient 或 OKHttp，让 OpenFeign 可以更好地对 HTTP 连接对象进行重用和管理，以提高其性能。 开启数据压缩功能，可以提高宽带利用率和加速数据传输速度。 使用合适的负载均衡策略来替换默认的轮询负载均衡策略，已获得更好的执行效率。 检查生成环境中 OpenFeign 的日志级别，选择合适的日志输出级别，防止无效的日志输出。 ","permalink":"https://habyss.github.io/posts/tech/openfeign/","summary":"一、超时优化 OpenFeign 底层内置了 Ribbon 框架，并且使用了 Ribbon 的请求连接超时时间和请求处理超时时间作为其超时时间，而 Ribbon 默认的请求连接超时时间和请求处理超时时间","title":"OpenFeign优化"},{"content":"pom 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;dependencies\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-ratelimiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-all\u0026lt;/artifactId\u0026gt; version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-spring-boot2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 想使用resilience4j的注解功能，需要引入aop --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 配置 您可以在springboot中配置断路器、重试、限流器、隔离、线程池隔离和限时器实例。使用application.yml进行配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 resilience4j.circuitbreaker: instances: backendA: registerHealthIndicator: true slidingWindowSize: 100 backendB: # 健康监控开启 registerHealthIndicator: true # 若COUNT_BASED，10次调用中有50%失败（即5次）打开熔断断路器； # 若TIME_BASED，在10秒内（sliding-window-size）100%（slow-call-rate-threshold）的请求超过2秒（slow-call-duration-threshold）打开断路器。 slidingWindowSize: 10 # 运行断路器在HALF_OPEN状态下时进行3次调用，如果故障或慢速调用仍然高于阈值，断路器再次进入打开状态。 permittedNumberOfCallsInHalfOpenState: 3 # 滑动窗口期类型 次数COUNT_BASED 时间TIME_BASED 默认COUNT_BASED。 slidingWindowType: TIME_BASED # 每个滑动窗口期 最少20次请求后生效 minimumNumberOfCalls: 20 # 一旦断路器是打开状态，它会拒绝请求50秒钟，然后转入半开状态。 waitDurationInOpenState: 50s # 50%的失败请求, 开启断路 failureRateThreshold: 50 eventConsumerBufferSize: 10 recordFailurePredicate: io.github.robwin.exception.RecordFailurePredicate resilience4j.retry: instances: backendA: maxRetryAttempts: 3 waitDuration: 10s enableExponentialBackoff: true exponentialBackoffMultiplier: 2 retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.io.IOException ignoreExceptions: - io.github.robwin.exception.BusinessException backendB: maxRetryAttempts: 3 waitDuration: 10s retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.io.IOException ignoreExceptions: - io.github.robwin.exception.BusinessException resilience4j.bulkhead: instances: backendA: maxConcurrentCalls: 10 backendB: maxWaitDuration: 10ms maxConcurrentCalls: 20 resilience4j.thread-pool-bulkhead: instances: backendC: maxThreadPoolSize: 1 coreThreadPoolSize: 1 queueCapacity: 1 resilience4j.ratelimiter: instances: backendA: # 限流10个 limitForPeriod: 10 # 每秒 limitRefreshPeriod: 1s # 被阻塞的线程最长等待时间, 超时会异常 timeoutDuration: 0 registerHealthIndicator: true # 被阻塞最大线程数量, 超出会异常 eventConsumerBufferSize: 100 backendB: limitForPeriod: 6 limitRefreshPeriod: 500ms timeoutDuration: 3s resilience4j.timelimiter: instances: backendA: timeoutDuration: 2s cancelRunningFuture: true backendB: timeoutDuration: 1s cancelRunningFuture: false 还可以覆盖默认配置，定义共享配置并在springboot中覆盖它们应用程序application.yml 配置文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 resilience4j.circuitbreaker: configs: default: slidingWindowSize: 100 permittedNumberOfCallsInHalfOpenState: 10 waitDurationInOpenState: 10000 failureRateThreshold: 60 eventConsumerBufferSize: 10 registerHealthIndicator: true someShared: slidingWindowSize: 50 permittedNumberOfCallsInHalfOpenState: 10 instances: backendA: baseConfig: default waitDurationInOpenState: 5000 backendB: baseConfig: someShared 通过代码覆盖默认配置 您还可以通过对特定实例名称使用Customizer来覆盖特定断路器、隔离、重试、限流器或限时器实例的配置。下面的示例演示了如何在配置的断路器backendA对上面的YAML文件进行覆盖。\n1 2 3 4 5 @Bean public CircuitBreakerConfigCustomizer testCustomizer() { return CircuitBreakerConfigCustomizer .of(\u0026#34;backendA\u0026#34;, builder -\u0026gt; builder.slidingWindowSize(100)); } Resilience4j有自己的customizer类型，可以按上图所示使用：\nResilienc4j类型 自定义类 Circuit breaker CircuitBreakerConfigCustomizer Retry RetryConfigCustomizer Rate limiter RateLimiterConfigCustomizer Bulkhead BulkheadConfigCustomizer ThreadPoolBulkhead ThreadPoolBulkheadConfigCustomizer Time Limiter TimeLimiterConfigCustomizer 切面的顺序 Resilience4j的切面执行顺序：\n1 Retry ( CircuitBreaker ( RateLimiter ( TimeLimiter ( Bulkhead ( Function ) ) ) ) ) 所以Retry 是最后执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @CircuitBreaker(name = BACKEND, fallbackMethod = \u0026#34;fallback\u0026#34;) @RateLimiter(name = BACKEND) @Bulkhead(name = BACKEND) @Retry(name = BACKEND, fallbackMethod = \u0026#34;fallback\u0026#34;) @TimeLimiter(name = BACKEND) public Mono\u0026lt;String\u0026gt; method(String param1) { return Mono.error(new NumberFormatException()); } private Mono\u0026lt;String\u0026gt; fallback(String param1, IllegalArgumentException e) { return Mono.just(\u0026#34;test\u0026#34;); } private Mono\u0026lt;String\u0026gt; fallback(String param1, RuntimeException e) { return Mono.just(\u0026#34;test\u0026#34;); } ","permalink":"https://habyss.github.io/posts/tech/resilience4j_%E7%86%94%E6%96%AD/","summary":"pom 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;dependencies\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-ratelimiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-all\u0026lt;/artifactId\u0026gt; version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-spring-boot2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 想使用resilienc","title":"resilience4j-spring-boot2 熔断"},{"content":"全局拦截, 在 MDC 中插入自定义 traceId 💡 MDC（Mapped Diagnostic Context）机制实现，支持主流的Log4j、Log4j2和Logback日志框架。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Order(Ordered.HIGHEST_PRECEDENCE) @Component @Slf4j public class TraceIdFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { // 服务间透传traceId String traceId = request.getHeader(TraceIdUtil.TRACE_ID); if (StringUtils.hasText(traceId)){ TraceIdUtil.resetTraceId(traceId); }else { TraceIdUtil.resetTraceId(); } log.info(\u0026#34;---请求地址: {} - {}\u0026#34;, request.getServletPath(), request.getQueryString()); chain.doFilter(request, response); } } 工具类 TraceIdUtils 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @UtilityClass public class TraceIdUtils { public final static String TRACE_ID = \u0026#34;traceId\u0026#34;; public final static String DELIMITER = \u0026#34;-\u0026#34;; public final static String EMPTY = \u0026#34;\u0026#34;; /** * 重置 traceId. * 为保证链路, 请求中有[异步/多线程]执行时, * 需先获取当前traceId{@link TraceIdUtils#getTraceId()}, 然后在新线程中设置traceId * * @param uuid the uuid */ public void resetTraceId(String uuid) { MDC.put(TRACE_ID, uuid); } /** * 重置/初始化 traceId. */ public void resetTraceId() { MDC.put(TRACE_ID, UUID.randomUUID().toString().replaceAll(DELIMITER, EMPTY)); } /** * 获取当前 traceId. * * @return the trace id */ public String getTraceId() { return MDC.get(TRACE_ID); } /** * 删除当前 traceId. */ public void remove() { MDC.remove(TRACE_ID); } } 日志输出配置文件 logback.xml 💡 在适当位置添加 %X{traceId} , 取出在 MDC 中设置的 traceId\n1 2 3 \u0026lt;pattern\u0026gt; %d{yyyy-MM-dd HH:mm:ss.SSS} %p %X{traceId} (%file:%line\\) - %m%n \u0026lt;/pattern\u0026gt; 微服务透传openFeign 在请求头中加入traceId, 并在TraceIdFilter中读取请求头\n1 2 3 4 5 6 7 8 9 @Component public class OpenFeignRequestInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate requestTemplate) { String traceId = TraceIdUtil.getTraceId(); requestTemplate.header(TraceIdUtil.TRACE_ID, traceId); } } ","permalink":"https://habyss.github.io/posts/tech/springboot_traceid/","summary":"全局拦截, 在 MDC 中插入自定义 traceId 💡 MDC（Mapped Diagnostic Context）机制实现，支持主流的Log4j、Log4j2和Logback日志框架。 1","title":"TraceId 日志跟踪"},{"content":"RabbitMq 生产者确认消息被消费 探索 消费者手动ack的一些状态, 生产者是不能准确得知的.\n例如:\n1 2 // 处理失败 重新进入队列 继续消费 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,true); 当消费者把消息重新放入队列, 生产者是不知道的\n….\n而 生产者的 convertSendAndReceive 虽然可以得知返回信息, 但是它是有次数限制的, 而次数是提前设定好的, 如果次数范围内没有处理成功, 则会接收到null.\n所以仍不能准确得知消费者的状态.\n生产者不能准确得知消费者是否成功消费了消息 配置文件 application.yml中增加配置\n1 2 3 4 spring: rabbitmq: publisher-confirms: true publisher-returns: true 生产者可以实现 RabbitTemplate.ReturnCallback, 来获取消息在发送到路由或者队列中的失败信息\n普通创建类方式\n定义ReturnCallBackService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Component public class ReturnCallBackService implements RabbitTemplate.ReturnCallback { /** * 发送到路由或者队列中的失败信息 * * @param message the returned message. * @param replyCode the reply code. * @param replyText the reply text. * @param exchange the exchange. * @param routingKey the routing key. */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) { System.out.println(\u0026#34;return--message:\u0026#34; + new String(message.getBody()) + \u0026#34;,replyCode:\u0026#34; + replyCode + \u0026#34;,replyText:\u0026#34; + replyText + \u0026#34;,exchange:\u0026#34; + exchange + \u0026#34;,routingKey:\u0026#34; + routingKey); } } 生产者发送消息之前设置\n1 rabbitTemplate.setReturnCallback(returnCallBackService); jdk8, 匿名函数\n发送消息之前设置\n1 2 3 4 rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -\u0026gt; { logger.info(\u0026#34;send message failed: \u0026#34; + replyCode + \u0026#34; \u0026#34; + replyText); rabbitTemplate.send(message); }); 生产者可以实现 RabbitTemplate.ConfirmCallback, 来确认消息是否发送到具体路由或者队列\n普通创建类方式\n定义ConfirmCallback\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component public class ConfirmCallbackService implements RabbitTemplate.ConfirmCallback { /** * 确认消息是否发送到具体路由或者队列 * * @param correlationData correlation data for the callback. * @param ack true for ack, false for nack * @param cause An optional cause, for nack, when available, otherwise null. */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { System.out.println(\u0026#34;correlationData.getId() = \u0026#34; + correlationData.getId()); System.out.println(\u0026#34;ack = \u0026#34; + ack); if (ack){ System.err.println(\u0026#34;===============消息发送成功============\u0026#34;); }else { //发送失败 System.err.println(\u0026#34;================失败==================\u0026#34;); } System.out.println(\u0026#34;cause = \u0026#34; + cause); } } 生产者发送消息之前设置\n1 rabbitTemplate.setConfirmCallback(confirmCallbackService); jdk8, 匿名函数\n发送消息之前设置\n1 2 3 4 5 6 7 8 9 rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -\u0026gt; { if (ack) { logger.info(\u0026#34;send message success: data [\u0026#34; + correlationData.getId() + \u0026#34;]\u0026#34;); // 清除重试机制缓存 // retryCache.del(Long.valueOf(correlationData.getId())); } else { logger.info(\u0026#34;send message failed: \u0026#34; + cause + correlationData.toString()); } }); 手动ack 消费者的 @RabbitListener 注解中有 containerFactory 字段, 可以指定一个自定义的 containerFactory .\n创建自定义可以手动ack的 containerFactory:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class ConsumeConfig { @Resource ConnectionFactory connectionFactory; @Bean(\u0026#34;rabbitListenerContainerFactoryAck\u0026#34;) public RabbitListenerContainerFactory\u0026lt;?\u0026gt; rabbitListenerContainerFactoryAck(){ SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); return factory; } } 在需要手动ack的方法上指定 bean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @RabbitListener(queues = \u0026#34;update.crm.staff\u0026#34;,containerFactory = \u0026#34;rabbitListenerContainerFactoryAck\u0026#34;) @RabbitHandler public void updateCrmStaff(Channel channel, Message msg){ System.err.println(\u0026#34;========================消费开始================\u0026#34;); try { byte[] body = msg.getBody(); String s = new String(body); JSONObject crmAgent = JSONObject.parseObject(s); // 处理失败 重新进入队列 继续消费 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,true); } catch (IOException e) { e.printStackTrace(); try { //处理失败,丢弃消息 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,false); } catch (IOException e1) { e1.printStackTrace(); } } // 手动确认消费 channel.basicAck(msg.getMessageProperties().getDeliveryTag(), false); System.err.println(\u0026#34;========================消费结束================\u0026#34;); } } ","permalink":"https://habyss.github.io/posts/tech/rabbitmq_ack/","summary":"RabbitMq 生产者确认消息被消费 探索 消费者手动ack的一些状态, 生产者是不能准确得知的. 例如: 1 2 // 处理失败 重新进入队列 继续消费 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,true); 当消费者把消息重新","title":"rabbitmq ack 探索"},{"content":"高并发情况下 RabbitMQ 服务限流 spring下默认为250, 若默写服务需要限流或者需要强制顺序性执行, 则需要自定义qos\n1 2 3 4 5 @RabbitHandler @RabbitListener(queues = QueueConstant.RE_SMS_ORDER_NOT_PAID_QUEUE) public void process(Channel channel, Message message) throws IOException { channel.basicQos(12); } 多个消费者同时消费一个消息 使用广播模式, 监听时不指定队列, 则会产生随即队列\n为了防止系统迭代重启产生的大量随机队列, 需要断开时删除随机队列\n1 2 3 4 5 @RabbitListener(bindings = @QueueBinding( //注意这里不要定义队列名称,系统会随机产生 value = @Queue(exclusive = \u0026#34;true\u0026#34;),// exclusive = \u0026#34;true\u0026#34; 断开时删除随机队列 避免系统迭代重启产生的大量随机队列 exchange = @Exchange(value = \u0026#34;填写交换机名称\u0026#34;, type = ExchangeTypes.FANOUT) )) ","permalink":"https://habyss.github.io/posts/tech/rabbitmq_qos_random/","summary":"高并发情况下 RabbitMQ 服务限流 spring下默认为250, 若默写服务需要限流或者需要强制顺序性执行, 则需要自定义qos 1 2 3 4 5 @RabbitHandler @RabbitListener(queues = QueueConstant.RE_SMS_ORDER_NOT_PAID_QUEUE) public void process(Channel channel, Message message)","title":"rabbitmq限流Qos 多个消费者同时消费一个消息"},{"content":"方式一: 原生RabbitMq延时队列 💡缺点: 每个队列的消息是顺序的, 靠后的过期时间短的消息并不能先执行\n配置队列 机制\n“死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况：\n消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。 消息在队列的存活时间超过设置的TTL时间。 消息队列的消息数量已经超过最大队列长度。 思路:\n声明一个默认队列 或 交换机绑定的队列, 不设置消费者, 称为死信队列 死信队列设置转发交换机以及路由 生产者设置消息过期时间 或 死信队列统一设置过期时间 过期后转发至新的交换机/队列进行消费 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 @Component public class DelayRabbitSmsOrderConfig { /** * 重发 */ public static final String RE_SMS_ORSER_EXCHANGE = \u0026#34;re.sms.order\u0026#34;; public static final String RE_SMS_ORDER_NOT_PAID_K = \u0026#34;re.sms.order.not.k.paid\u0026#34;; public static final String RE_SMS_ORDER_NOT_PAID_QUEUE = \u0026#34;re.sms.order.not.q.paid\u0026#34;; /** * 死信 */ public static final String DL_SMS_ORSER_EXCHANGE = \u0026#34;dead.sms.order\u0026#34;; public static final String DL_SMS_ORDER_NOT_PAID_K = \u0026#34;dead.sms.order.not.k.paid\u0026#34;; public static final String DL_SMS_ORDER_NOT_PAID_QUEUE = \u0026#34;dead.sms.order.not.q.paid\u0026#34;; /** * 声明重发交换机 */ @Bean public Exchange reExchange() { return ExchangeBuilder .directExchange(RE_SMS_ORSER_EXCHANGE) .durable(true) .build(); } /** * 声明重发队列 */ @Bean public Queue reQueue() { return QueueBuilder .durable(RE_SMS_ORDER_NOT_PAID_QUEUE) .build(); } /** * 绑定重发交换机 重发路由 */ @Bean public Binding reExchangeBinding(Exchange reExchange, Queue reQueue) { return BindingBuilder .bind(reQueue) .to(reExchange) .with(RE_SMS_ORDER_NOT_PAID_K) .noargs(); } /** * 声明死信队列 */ @Bean public Queue dlQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(4); // 指定过期之后的交换机为重发交换机 args.put(\u0026#34;x-dead-letter-exchange\u0026#34;, RE_SMS_ORSER_EXCHANGE); // 指定过期之后的路由为重发路由 args.put(\u0026#34;x-dead-letter-routing-key\u0026#34;, RE_SMS_ORDER_NOT_PAID_K); // 统一的毫秒单位过期 如果过期时间是动态的,需要rabbitMq插件,并在每条消息上设置过期时间 args.put(\u0026#34;x-expires\u0026#34;, \u0026#34;600000\u0026#34;); return QueueBuilder .durable(DL_SMS_ORDER_NOT_PAID_QUEUE) .withArguments(args) .build(); } // 下面两个可不设置, 则消费者发消息的时候不设置交换机和路由(即使用默认的交换机) /** * 声明死信交换机 */ @Bean public Exchange dlExchange() { return ExchangeBuilder .directExchange(DL_SMS_ORSER_EXCHANGE) .durable(true) .build(); } /** * 绑定死信交换机 死信路由 */ @Bean public Binding dlExchangeBinding(Exchange dlExchange, Queue dlQueue) { return BindingBuilder .bind(dlQueue) .to(dlExchange) .with(DL_SMS_ORDER_NOT_PAID_K) .noargs(); } } 生产者 1 2 3 4 5 6 7 8 9 10 11 12 // 延时 创单10min未支付 Message msg = MessageBuilder.withBody(params.getBytes()) .setContentType(MessageProperties.CONTENT_TYPE_JSON) .setContentEncoding(\u0026#34;utf-8\u0026#34;) // 若上面配置设置了死信交换机/死信路由 则配置上 .setReceivedExchange(\u0026#34;\u0026#34;) .setReceivedRoutingKey(\u0026#34;\u0026#34;) .setMessageId(UUID.randomUUID() + \u0026#34;\u0026#34;) // 若上面配置设置了统一的毫秒单位过期, 则不用配置 .setExpiration(\u0026#34;600000\u0026#34;) .build(); amqpTemplate.convertAndSend(QueueConstant.DEAD_SMS_ORDER_QUEUE, msg); 消费者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Component public class SmsPushNotPaidReceiver { public static final Logger logger = LoggerFactory.getLogger(SmsPushNotPaidReceiver.class); @RabbitHandler // 监听重发队列 @RabbitListener(queues = QueueConstant.RE_SMS_ORDER_NOT_PAID_QUEUE) public void process(Message message) { logger.info(\u0026#34;----------- sms.notPayOrder start -----------\u0026#34;); String params = new String(message.getBody(), StandardCharsets.UTF_8); JSONObject param = JSONObject.parseObject(params); String code = param.getString(\u0026#34;code\u0026#34;); logger.info(\u0026#34;----------- sms.notPayOrder end -----------\u0026#34;); } } 方式二: 插件RabbitMq延时队列 💡 没有了原生的缺点..\n💡 需要在服务器上自己装延时队列的插件, 简单\n配置队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Bean CustomExchange delayExchange() { //创建一个自定义交换机，可以发送延迟消息 Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-delayed-type\u0026#34;, \u0026#34;direct\u0026#34;); return new CustomExchange(QueueEnum.QUEUE_CONSULTATION_END.getExchange(), \u0026#34;x-delayed-message\u0026#34;, true, false, args); } // 添加其他延时队列时, 重复下面两个 @Bean public Queue consultationEndDelayQueue() { return new Queue(QueueEnum.QUEUE_CONSULTATION_END.getQueueName(), true); } @Bean public Binding consultationEndDelayBinding(CustomExchange delayExchange, Queue consultationEndDelayQueue) { return BindingBuilder .bind(consultationEndDelayQueue) .to(delayExchange) .with(QueueEnum.QUEUE_CONSULTATION_END.getRoutingKey()) .noargs(); } 生产者 1 2 3 4 5 6 7 8 9 10 11 CommonEvent commonEvent = new CommonEvent().setId(id); long delayTime = timeoutConstant.getImageTextAutoEnd() * 60 * 60 * 1000L; rabbitTemplate.convertAndSend( QueueEnum.QUEUE_CONSULTATION_END.getExchange(), QueueEnum.QUEUE_CONSULTATION_END.getRoutingKey(), commonEvent, message -\u0026gt; { //给消息设置延迟毫秒值 message.getMessageProperties().setHeader(\u0026#34;x-delay\u0026#34;, delayTime); return message; }); 消费者 1 2 3 4 5 6 7 8 9 @Component @RabbitListener(queues = \u0026#34;consultation.end\u0026#34;) public class ConsultationCancelReceiver { @RabbitHandler public void handle(CommonEvent commonEvent) { } } ","permalink":"https://habyss.github.io/posts/tech/rabbitmq_delay/","summary":"方式一: 原生RabbitMq延时队列 💡缺点: 每个队列的消息是顺序的, 靠后的过期时间短的消息并不能先执行 配置队列 机制 “死信”是RabbitMQ","title":"rabbitmq实现延时队列"},{"content":"方式一: 基于表达式 例如简单日志打印: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Slf4j @Aspect @Component public class WebLogAspect { /** * xxx包及其子包下的以Controller结尾的类的任意方法 */ @Pointcut(\u0026#34;execution(public * com.xxx..*Controller.*(..))\u0026#34;) public void webLog(){} @Around(\u0026#34;webLog()\u0026#34;) public Object around(ProceedingJoinPoint jp) throws Throwable { StopWatch sw = new StopWatch(\u0026#34;请求耗时\u0026#34;); ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = Objects.requireNonNull(attributes).getRequest(); sw.start(); log.info(\u0026#34;---请求来源 : {}\u0026#34;, IpUtil.getIpAddress(request)); log.info(\u0026#34;---请求方法 : {}.{}\u0026#34;, jp.getSignature().getDeclaringTypeName(), jp.getSignature().getName()); log.info(\u0026#34;---请求参数 : {}\u0026#34;, Arrays.toString(jp.getArgs())); Object result = jp.proceed(); sw.stop(); log.info(\u0026#34;---请求耗时 : {}{}\u0026#34;, sw.getLastTaskTimeMillis(), \u0026#34;ms\u0026#34;); log.info(\u0026#34;---请求返回 : {}\u0026#34;, result); return result; } } 方式二: 基于注解 说明\n@Target({ElementType.TYPE, ElementType.METHOD}) ：允许使用的地方；如-ElementType.TYPE==》类；ElementType.METHOD==》方法\n@Retention(RetentionPolicy.RUNTIME)：注解保留在程序运行期间，此时可以通过反射获得定义在某个类上的所有注解\n@Inherited：当@Inherited修饰过的注解加在某个类A上时，假如类B继承了A，则B也会带上该注解。加在接口上无效\n例如基于注解的redis缓存实现: 定义注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Retention(RetentionPolicy.RUNTIME) // 一般是运行时 @Target(ElementType.METHOD) // 注解级别 此处为方法级 @Order(Ordered.HIGHEST_PRECEDENCE) // 优先级 public @interface RedisCache { /** * key * * @return {@link String} */ String key(); /** * 过期时间 * * @return int */ long expire() default 1; /** * 时间单位 * * @return {@link TimeUnit} */ TimeUnit timeUnit() default TimeUnit.DAYS; /** * 方法返回为list集合时 必传 否则出错 * * @return {@link Class} */ Class\u0026lt;?\u0026gt; listForClass() default RedisCache.class; } 为注解增加aop相关实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Aspect @Component @Slf4j public class RedisCacheContract { @Resource RedisUtil redisUtil; @Around(\u0026#34;@annotation(redisCache)\u0026#34;) public Object redisAround(final ProceedingJoinPoint joinPoint, RedisCache redisCache) throws Throwable { Object result; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); String key = redisCache.key() + \u0026#34;:\u0026#34; + Arrays.toString(joinPoint.getArgs()); if (redisUtil.hasKey(key)) { log.info(\u0026#34;hint redisCache {}\u0026#34;, key); // 默认注解 直接使用原方法的returnType来解析json if (redisCache.listForClass().isAssignableFrom(RedisCache.class)) { Class\u0026lt;?\u0026gt; returnType = signature.getReturnType(); result = redisUtil.get(key, returnType); if (result instanceof ResponseResult\u0026lt;?\u0026gt; r) { // 设置新的traceId r.setTraceId(TraceIdUtil.getTraceId()); } } else { // list注解, 使用自定义class解析为List result = redisUtil.getAsList(key, redisCache.listForClass()); } } else { result = joinPoint.proceed(); redisUtil.set(key, result, redisCache.expire(), redisCache.timeUnit()); } return result; } } 限制ip示例: 定义注解\n1 2 3 4 5 6 7 8 9 10 11 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) @Order(Ordered.HIGHEST_PRECEDENCE) public @interface RequestLimit { int count() default Integer.MAX_VALUE; long time() default 60000; boolean limitIp() default false; } 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 /** * @author kun.han * 如果有网关的话 做在网关 */ @Slf4j @Aspect @Component public class RequestLimitContract { @Resource RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; private final static String KEY_PREFIX = \u0026#34;requestLimit:\u0026#34;; @Before(\u0026#34;@annotation(requestLimit)\u0026#34;) public void requestLimit(final JoinPoint joinPoint, RequestLimit requestLimit) { ValueOperations\u0026lt;String, String\u0026gt; ops = redisTemplate.opsForValue(); log.info(\u0026#34;limit - count\u0026#34; + requestLimit.count() + \u0026#34; time\u0026#34; + requestLimit.time()); // 1. redis获取设置用户的count, 过期时间为time 判断是否拦截 long userId = 123123123L; String userKey = KEY_PREFIX + userId; Long count = ops.increment(userKey); count = Objects.isNull(count) ? 0 : count; if (count \u0026gt; requestLimit.count()) { throw new ServiceException(\u0026#34;限制访问\u0026#34;); } if (requestLimit.limitIp()) { // 2. ip拦截 redis获取设置ip的count, 过期时间为time 判断是否拦截 String ip = IpUtil.getIpAddress(); userKey = KEY_PREFIX + ip.replaceAll(\u0026#34;\\\\.\u0026#34;, \u0026#34;-\u0026#34;); count = ops.increment(userKey); count = Objects.isNull(count) ? 0 : count; if (count \u0026gt; requestLimit.count()) { throw new ServiceException(\u0026#34;限制访问\u0026#34;); } log.info(ip); } } } 💡 一般情况下, 这两种足够使用了.\n","permalink":"https://habyss.github.io/posts/tech/springboot_aop/","summary":"方式一: 基于表达式 例如简单日志打印: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Slf4j @Aspect @Component public class WebLogAspect { /** * xxx包及其子包下的以Contro","title":"基于springboot常用aop方式"},{"content":"UML类图关系 💡 UML 全称Unified Modeling Language, 统计建模语言.\nUML类图中有六种关系，从弱到强依次是：\n依赖关系 \u0026lt; 关联关系 \u0026lt; 聚合关系 \u0026lt; 组合关系 \u0026lt; 实现关系 = 泛化关系\n类的成员变量和方法前面的修饰符有public, private, protected, default，在UML类图中分别用 +, -, #, ~表示。\n1. 依赖关系 通用描述: 依赖关系表示某个类依赖于另外一个类\n代码表现: 某个类的方法的参数使用了另外一个类的对象\n箭头描述: 依赖关系使用带箭头的虚线表示, 箭头指向被依赖的类\n示例图样:\n2. 关联关系 通用描述: 关联关系表示一个类和另外一个类的联系, 如老师和学生\n代码表现: 某个类的成员变量是另外一个类的对象\n箭头描述: 依赖关系有单向和双向, 单向使用带箭头的实线表示, 箭头指向被关联的类, 双向使用双箭头或者没有箭头的实线表示.\n示例图样:\n3. 聚合关系 通用描述: 聚合关系是关联关系的一种, 表示的是整体与部分之间的关系, 如学校和老师, 车子和轮胎\n代码表现: 某个类的成员变量是另外一个类的对象\n箭头描述: 聚合关系使用带空心菱形的实线表示, 菱形指向整体\n示例图样:\n4. 组合关系 通用描述: 组合关系是关联关系的一种, 是一种比聚合关系更强的一种关系, 部分不能脱离整体而单独存在, 如身体和大脑\n代码表现: 某个类的成员变量是另外一个类的对象\n箭头描述: 组合关系使用带实心菱形的实线表示, 菱形指向整体\n示例图样:\n5. 实现关系 通用描述: 实现关系是接口和实现类之间的关系\n代码表现: 接口和实现类\n箭头描述: 实现关系使用带空心三角箭头的虚线表示, 箭头指向接口\n示例图样:\n6. 泛化关系 通用描述: 泛化关系是父子类之间的继承关系\n代码表现: 抽象父子与子类, 继承\n箭头描述: 泛化关系使用带空心三角箭头的实线来表示, 箭头指向父类\n示例图样:\n总结 依赖关系 \u0026lt; 关联关系 \u0026lt; 聚合关系 \u0026lt; 组合关系 \u0026lt; 实现关系 = 泛化关系 关系名称 代码表现 箭头形式 箭头指向 依赖关系 方法参数 虚线箭头 指向被依赖的类(方法参数的类) 关联关系 成员变量 实线箭头 指向被关联的类(成员变量的类) 聚合关系 成员变量 实线空心菱形 指向整体 组合关系 成员变量 实线实心菱形 指向整体 实现关系 接口与实现类 虚线空心三角 指向接口 泛化关系 抽象父类与子类 实线空心三角 指向父类 ","permalink":"https://habyss.github.io/posts/tech/uml/","summary":"UML类图关系 💡 UML 全称Unified Modeling Language, 统计建模语言. UML类图中有六种关系，从弱到强依次是： 依赖关系 \u0026lt; 关联关系 \u0026lt; 聚合关系 \u0026lt; 组合关系 \u0026lt; 实现关","title":"UML类图关系"},{"content":"@Transactional失效 整合shiro之后，UserRealm类里自动注入的service中的@Transactional注解失效\n解决方法 使用@Lazy注解\n1 2 3 @Autowired @Lazy private OperationUnitService operationUnitService; 在Realm中直接使用mapper，而不是service\n1 2 @Autowired private OperationUnitMapper operationUnitMapper; ApplicationContextRegister.getBean()方法，手动注入bean\n1 OperationUnitService operationUnitService = ApplicationContextRegister.getBean(OperationUnitService.class) 产生原因 在shiro中为了引入权限注解，配置了defaultAdvisorAutoProxyCreator和authorizationAttributeSourceAdvisor类，他们是通过AOP方式对@RequiredPermission类/方法(权限控制)进行增强.\n生成对应的代理类对象，由于shiroFilterFactoryBean实现了factoryBean接口，所以会被提前初始化，所以引发所有相关的bean提前初始化，导致他们没有被事务AOP包裹着，从而引发事务无效的问题\n1 2 3 4 5 6 7 8 9 10 11 /** * 开启Shiro的注解(如@RequiresRoles,@RequiresPermissions),需借助SpringAOP扫描使用Shiro注解的类,并在必要时进行安全逻辑验证 * 配置以下两个bean(DefaultAdvisorAutoProxyCreator(可选)和AuthorizationAttributeSourceAdvisor)即可实现此功能 */ @Bean @DependsOn({\u0026#34;lifecycleBeanPostProcessor\u0026#34;}) public DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator() { DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); advisorAutoProxyCreator.setProxyTargetClass(true); return advisorAutoProxyCreator; } 元素的 \u0026ldquo;proxy-target-class\u0026rdquo; 属性值来控制是基于接口的还是基于类的代理被创建。如果 \u0026ldquo;proxy-target-class\u0026rdquo; 属值被设置为 \u0026ldquo;true\u0026rdquo;，那么基于类的代理将起作用（这时需要CGLIB库cglib.jar在CLASSPATH中）。如果 \u0026ldquo;proxy-target-class\u0026rdquo; 属值被设置为 \u0026ldquo;false\u0026rdquo; 或者这个属性被省略，那么标准的JDK基于接口的代理将起作用。\n工具 快捷查看事务是否生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class DebugUtils { private static final boolean transactionDebugging = true; private static final boolean verboseTransactionDebugging = true; public static void showTransactionStatus(String message) { System.out.println(((transactionActive()) ? \u0026#34;[+] \u0026#34; : \u0026#34;[-] \u0026#34;) + message); } // Some guidance from: \u0026lt;http://java.dzone.com/articles/monitoring-declarative-transac?page=0,1\u0026gt; public static boolean transactionActive() { try { ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); Class tsmClass = contextClassLoader.loadClass(\u0026#34;org.springframework.transaction.support.TransactionSynchronizationManager\u0026#34;); Boolean isActive = (Boolean) tsmClass.getMethod(\u0026#34;isActualTransactionActive\u0026#34;, null).invoke(null, null); return isActive; } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (IllegalArgumentException e) { e.printStackTrace(); } catch (SecurityException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } catch (NoSuchMethodException e) { e.printStackTrace(); } // If we got here it means there was an exception throw new IllegalStateException(\u0026#34;ServerUtils.transactionActive was unable to complete properly\u0026#34;); } public static void transactionRequired(String message) { // Are we debugging transactions? if (!transactionDebugging) { // No, just return return; } // Are we doing verbose transaction debugging? if (verboseTransactionDebugging) { // Yes, show the status before we get to the possibility of throwing an exception showTransactionStatus(message); } // Is there a transaction active? if (!transactionActive()) { // No, throw an exception throw new IllegalStateException(\u0026#34;Transaction required but not active [\u0026#34; + message + \u0026#34;]\u0026#34;); } } } 在需要检测的地方\n1 DebugUtils.transactionRequired(\u0026#34;OperationUnitServiceImpl.testIn\u0026#34;); ","permalink":"https://habyss.github.io/posts/tech/transactional/","summary":"@Transactional失效 整合shiro之后，UserRealm类里自动注入的service中的@Transactional注解失效 解","title":"@Transactional失效排查"},{"content":"$ref-fastjson 问题排查 问题排查 项目返回的数据中出现$ref数据\n查询得知是fastjson的特性循环引用 fastjson支持循环引用，并且是缺省打开的。\n当序列化后的JSON传输到浏览器或者其他语言中，这些json解析器不支持循环引用，从而导致数据丢失。你可以关闭fastjson的循环引用支持。关闭引用检测，还能够提升序列化时的性能。\n全局配置关闭\n1 JSON.DEFAULT_GENERATE_FEATURE |= SerializerFeature.DisableCircularReferenceDetect.getMask(); 非全局关闭\n1 JSON.toJSONString(obj, SerializerFeature.DisableCircularReferenceDetect); 项目中配置了全局默认使用fastjson, 所以导致默认的jackson不生效. $ref-fastjson-解决方案 全局配置关闭\n非全局关闭\n删除全局默认fastjson\n","permalink":"https://habyss.github.io/posts/tech/ref-fastjson/","summary":"$ref-fastjson 问题排查 问题排查 项目返回的数据中出现$ref数据 查询得知是fastjson的特性循环引用 fastjson支持循环引用，并且是缺省打开的。 当","title":"$ref-fastjson排查"},{"content":"SpringBoot中时间戳和LocalDateTime相关的接收和转换 前言 一般情况下, 前端和后端在时间格式的传递上都走的是时间戳（方便前端自由定制） 时间格式由于java8的新增时间处理类比较好用,而且更加线程安全, 所以将项目中的时间相关改为LocalDateTime，而不是传统的Date 前置要求 mybatis需要3.4.6以上, 否则会不支持xml和javaType的转换 druid需要比较新的版本, 这里使用的是1.1.21, 否则查询会报错,结果集result set中找不到元素 正文 请求方式的情况分类\n@RequestBody中修饰LocalDateTime 其他, 比如@RequestParam和@PathVariable以及不加注解的单参数和对象参数 情况一. @RequestBody中的LocalDateTime 通过@RequestBody很明显的就是要通过JSON序列化进行处理，Spring默认的是Jackson进行处理，所以我们需要对默认的JSON处理器进行日期类型的添加(假如默认不带对应序列化器的情况下)\n此时需要用的是JsonDeserializer这个类，对应的实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * 入参 时间戳 -\u0026gt; LocalDateTime */ public class CustomDateDeserializer { public static class LocalDateTimeDeserializer extends JsonDeserializer\u0026lt;LocalDateTime\u0026gt; { @Override public LocalDateTime deserialize(JsonParser p, DeserializationContext context) throws IOException { Long timestamp = Long.valueOf(p.getText()); Instant instant = Instant.ofEpochMilli(timestamp); return LocalDateTime.ofInstant(instant, ZoneId.systemDefault()); } } } /** * @author kun.han on 2020/3/4 15:45 * 返回参数 LocalDateTime -\u0026gt; 时间戳 */ public class CustomDateSerializer { public static class LocalDateTimeSerializer extends JsonSerializer\u0026lt;LocalDateTime\u0026gt; { @Override public void serialize(LocalDateTime localDateTime, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException { jsonGenerator.writeNumber(localDateTime.toInstant(ZoneOffset.of(\u0026#34;+8\u0026#34;)).toEpochMilli()); } } } 有了这个了类，还需要添加到Spring中，Spring利用的是ObjectMapper，我们自定义一个ObjectMapper替换原本的就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Configuration public class CustomDateConfig implements WebMvcConfigurer { /** * Json序列化和反序列化转换器，用于转换Post请求体中的json以及将我们的对象序列化为返回响应的json */ @Bean public ObjectMapper objectMapper() { ObjectMapper objectMapper = new ObjectMapper(); //不显示为null的字段 objectMapper.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS); objectMapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); // 忽略不能转移的字符 objectMapper.configure(JsonParser.Feature.ALLOW_BACKSLASH_ESCAPING_ANY_CHARACTER, true); // 过滤对象的null属性. objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); //忽略transient objectMapper.configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true); objectMapper.disable(DeserializationFeature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE); //LocalDateTime系列序列化和反序列化模块，继承自jsr310，我们在这里修改了日期格式 JavaTimeModule javaTimeModule = new JavaTimeModule(); // LocalDateTime 这里只需要LocalDateTime 如果需要转其他的,相应放开注释, 并在上面两个类中适当修改 javaTimeModule.addSerializer(LocalDateTime.class, new CustomDateSerializer.LocalDateTimeSerializer()); javaTimeModule.addDeserializer(LocalDateTime.class,new CustomDateDeserializer.LocalDateTimeDeserializer()); // // LocalDate // javaTimeModule.addSerializer(LocalDate.class, new CustomDateSerializer.LocalDateSerializer()); // javaTimeModule.addDeserializer(LocalDate.class, new CustomDateDeserializer.LocalDateDeserializer()); // //Date序列化和反序列化 // javaTimeModule.addSerializer(Date.class,new CustomDateSerializer.DateSerializer()); // javaTimeModule.addDeserializer(Date.class,new CustomDateDeserializer.DateDeserializer()); objectMapper.registerModule(javaTimeModule); return objectMapper; } } 情况二. 其他 比如@RequestParam和@PathVariable以及不加注解的单参数和对象参数 方式一: Convert 可以根据自身需求进行定制，这里我通过Convert转换LocalDateTime为例，进行转换：\n1 2 3 4 5 6 7 8 9 public class CustomDateConverter { public static class LocalDateConvert implements Converter\u0026lt;String, LocalDateTime\u0026gt; { @Override public LocalDateTime convert(String timestamp) { return LocalDateTime.ofInstant(Instant.ofEpochMilli(Long.parseLong(timestamp)), ZoneId.systemDefault()); } } } 同样的需要在配置类中引用\n1 2 3 4 5 6 7 8 @Configuration public class CustomDateConfig implements WebMvcConfigurer { @Bean public Converter\u0026lt;String, LocalDateTime\u0026gt; localDateConverter() { //此处不能替换为lambda表达式 return new CustomDateConverter.LocalDateConvert(); } } 方式二: ControllerAdvice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * requestBody之外的入参 时间戳-\u0026gt;LocalDateTime * * @author hankun */ @ControllerAdvice public class LocalDateTimeAdvice { @InitBinder protected void initBinder(WebDataBinder binder) { // 这里只需要LocalDateTime 如果需要转其他的,相应添加/修改 binder.registerCustomEditor(LocalDateTime.class, new PropertyEditorSupport() { @Override public void setAsText(String timestamp) throws IllegalArgumentException { if (!StringUtils.hasText(timestamp)) { setValue(null); } else { setValue(LocalDateTime.ofInstant(Instant.ofEpochMilli(Long.parseLong(timestamp)), ZoneId.systemDefault())); } } }); // 这里只需要LocalDateTime 如果需要转其他的,相应添加/修改 binder.registerCustomEditor(LocalDate.class, new PropertyEditorSupport() { @Override public void setAsText(String timestamp) throws IllegalArgumentException { if (!StringUtils.hasText(timestamp)) { setValue(null); } else { setValue(LocalDate.ofInstant(Instant.ofEpochMilli(Long.parseLong(timestamp)), ZoneId.systemDefault())); } } }); } } 相关知识点 时间差 精确时间差:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 long start = 1584328558000L; long now = 1584400558000L; Instant startTime = Instant.ofEpochMilli(start); LocalDateTime startTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()); Instant endTime = Instant.ofEpochMilli(now); LocalDateTime entTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()); Duration duration = Duration.between(startTimeT, entTimeT); // Duration duration = Duration.between(startTime, entTime); long day = duration.toDays(); long hours = duration.toHours(); long min = duration.toMinutes(); long millis= duration.toMillis(); long nanos = duration.toNanos(); 粗略时间差, 比如今天明天算一天\n1 2 3 4 5 6 7 8 9 10 11 long start = 1584328558000L; long now = 1584400558000L; Instant startTime = Instant.ofEpochMilli(start); LocalDate startTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()).toLocalDate(); Instant endTime = Instant.ofEpochMilli(now); LocalDate entTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()).toLocalDate(); Period period = Period.between(startTimeT, entTimeT); int years = period.getYears(); int months = period.getMonths(); int days = period.getDays(); ","permalink":"https://habyss.github.io/posts/tech/springboot_localdatetime/","summary":"SpringBoot中时间戳和LocalDateTime相关的接收和转换 前言 一般情况下, 前端和后端在时间格式的传递上都走的是时间戳（方便前端","title":"SpringBoot中时间戳和LocalDateTime相关的接收和转换"},{"content":"小鹤双拼 方案一 win + R，输入 regedit，打开注册表\n找到 计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\InputMethod\\Settings\\CHS 项\n新建一个名为 UserDefinedDoublePinyinScheme0 的字符串值，值为\n1 小鹤双拼*2*^*iuvdjhcwfg^xmlnpbksqszxkrltvyovt 方案二 新建文本文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Windows Registry Editor Version 5.00 [HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\InputMethod\\Settings\\CHS] \u0026#34;EnableExtraDomainType\u0026#34;=dword:00000001 \u0026#34;EnableSmartSelfLearning\u0026#34;=dword:00000000 \u0026#34;EnableVMode\u0026#34;=dword:00000000 \u0026#34;EnableHap\u0026#34;=dword:00000000 \u0026#34;EnablePeopleName\u0026#34;=dword:00000000 \u0026#34;DoublePinyinScheme\u0026#34;=dword:0000000a \u0026#34;EnableUMode\u0026#34;=dword:00000000 \u0026#34;EnableSmartFuzzyPinyin\u0026#34;=dword:00000000 \u0026#34;UserDefinedDoublePinyinScheme0\u0026#34;=\u0026#34;小鹤双拼*2*^*iuvdjhcwfg^xmlnpbksqszxkrltvyovt\u0026#34; \u0026#34;Enable Dynamic Candidate Ranking\u0026#34;=dword:00000000 \u0026#34;Enable self-learning\u0026#34;=dword:00000000 \u0026#34;Expand Double Pinyin\u0026#34;=dword:00000000 \u0026#34;Enable Double Pinyin\u0026#34;=dword:00000001 \u0026#34;LangBar Force On\u0026#34;=dword:00000000 \u0026#34;PinyinMixEnable\u0026#34;=dword:00000000 \u0026#34;ToolBarEnabled\u0026#34;=dword:00000000 重命名.reg, 并运行\n","permalink":"https://habyss.github.io/posts/tool/%E5%B0%8F%E9%B9%A4%E5%8F%8C%E6%8B%BC/","summary":"小鹤双拼 方案一 win + R，输入 regedit，打开注册表 找到 计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\I","title":"小鹤双拼"},{"content":"Mysql-explain id id相同时, 执行顺序由上而下 id不同时, 执行顺序由大到小, 一般为子查询 select_type 查询类型, 常见的值有:\nSIMPLE: 简单查询, 不包含UNION或者子查询 PRIMARY: 查询中如果包含子查询或其他部分, 则外层的SELECT将被标记为PRIMARY SUBQUERY: 子查询中的第一个SELECT NUION: 在UNION语句中, UNION之后出现的SELECT DERIVED: 在FROM中出现的子查询 UNION RESULT: UNION查询的结果 table 当前的数据表\npartitions 查询所匹配记录的分区, 对于未分区的表, 值为NULL\ntype 查询执行的类型, 最优排行\nsystem \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; fulltext \u0026gt; ref_or_null \u0026gt; index_merge \u0026gt; unique_subquery \u0026gt; index_subquery \u0026gt; range \u0026gt; index \u0026gt; ALL\nsystem: 表中只有一行数据, 是const的一种特例 const: 表中最多只有一行匹配的记录 eq_ref: 连表查询时, 前一张表的行在当前表中只有一行与之对应(除了system与const最好的连表方式) ref: 使用普通索引作为查询条件, 查询结果可能找到多行匹配的记录 fulltext: 全文索引 ref_or_null: 使用普通索引作为查询条件 , 查询结果可能找到多行匹配的记录, 还查询了值为NULL的行 index_merge: 当查询条件使用多个索引时, index_merge表示开启了Index Merge优化 unique_subquery: eq_ref类似, 在一些使用IN的子查询中, 使用唯一索引 index_subquery: 与unique_subquery类似, 在IN子查询中, 使用了普通索引 range: 对索引列进行范围查询 index: 查询便利了整个索引树, ALL: 遍历全表, 很可能读磁盘, 速度最慢 possible_key 可能被使用的索引, 不一定被查询实际使用\nkey 查询中实际使用到的索引, 如果为NULL, 则表示为建立索引或索引失效\nkey_len 查询索引时使用的字节数, 在满足前提的需求下, 越小越好\nref 在查询索引时, 那些列或常量被用来与索引值比较\nrows 可能查询时需要遍历的行数\nfiltered 估算经过查询条件筛选出的列数的百分比\nExtra 查询时的额外信息\n当包含Using filesort或Using temporary, 需要优化\nUsing filesort: 在排序时使用了外部的索引排序, 没有使用表内的索引进行排序 Using temporary: 需要创建临时表来存储查询的结果, 常见于ORDER BY和GROUP BY Using index: 使用了索引覆盖, 查询效率非常高 Using where: 使用了WHERE子句进行条件过滤, 一般在没有使用到索引的时候出现 Impossible where: 表示where子句的结果总是false且无法查到任意行 Using join buffer(Block Nested Loop): 连表查询时, 当被驱动表没有使用索引时, 会先将驱动表读到join buffer中, 再遍历被驱动表与驱动表进行查询 Using json buffer(Batched Key Access): 与Using join buffer(Block Nested Loop)类似, 使用的是BKA算法\u0026ndash; 前提是被驱动表有索引可用 ","permalink":"https://habyss.github.io/posts/tech/mysql_explain/","summary":"Mysql-explain id id相同时, 执行顺序由上而下 id不同时, 执行顺序由大到小, 一般为子查询 select_type 查询类型, 常见的值有: SIMPLE: 简单查询, 不包含UNION或者子查询 PRIMARY: 查","title":"Mysql Explain 简解"},{"content":"Hugo+Github Pages 1. 安装Scoop win系统, 在hugo官网中也推荐了使用Scoop来进行包管理\n打开PowerShell并运行, 保证允许本地脚本的执行\n1 set-executionpolicy remotesigned -scope currentuser 执行安装命令\n1 iex (new-object net.webclient).downloadstring(\u0026#39;https://get.scoop.sh\u0026#39;) 安装成功验证\n1 scoop help 2. 安装Hugo 安装Hugo的extend版本\n1 scoop install hugo-extended 安装成功验证\n1 hugo version 3. 创建Blog hugo new site MyBlog -f yml 下载zip解压到themes, 并重命名为PaperMod 修改config.yml https://shaohanyun.top/posts/env/blog_build2/\nhttps://www.sulvblog.cn/posts/blog/build_hugo/\n","permalink":"https://habyss.github.io/posts/tech/%E6%B5%8B%E8%AF%95/","summary":"Hugo+Github Pages 1. 安装Scoop win系统, 在hugo官网中也推荐了使用Scoop来进行包管理 打开PowerShell并运行, 保证允许本地脚本的执行 1 set-executionpolicy","title":"测试"}]