[{"content":"简单demo实现 简单实现, 以大文件的md5作为唯一key\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 @Slf4j @Api(tags = \u0026#34;大文件上传\u0026#34;) @RestController @RequestMapping(\u0026#34;dict\u0026#34;) public class BigFileController { public static final String tmpPath = \u0026#34;E:/data/tempAppfiles/\u0026#34;; public static final String finalPath = \u0026#34;E:/data/finalAppfiles/\u0026#34;; private static final Map\u0026lt;String, Integer\u0026gt; chunkMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * 上传文件 * * @param dto dto * @return {@link String} */ @PostMapping(\u0026#34;uploadFile\u0026#34;) public ResponseResult\u0026lt;?\u0026gt; uploadFile(UploadFileDTO dto) { String md5 = dto.getMd5().toLowerCase(); String tmpFileName = tmpPath + md5 + \u0026#34;/\u0026#34; + dto.getIndex() + \u0026#34;.tmp\u0026#34;; // 分片秒传 if (chunkMap.get(tmpFileName) != null) { return ResponseResult.createBySuccess(); } createTmpPath(tmpPath + md5); try { FileCopyUtils.copy(dto.getFile().getBytes(), new File(tmpFileName)); } catch (IOException e) { e.printStackTrace(); throw new ServiceException(\u0026#34;文件上传失败\u0026#34;); } chunkMap.put(tmpFileName, dto.getIndex()); return ResponseResult.createBySuccess(); } /** * 合并文件 * * @param dto dto * @return {@link String} */ @PostMapping(\u0026#34;mergeFile\u0026#34;) public ResponseResult\u0026lt;?\u0026gt; mergeFile(@RequestBody MergeFileDTO dto) { String md5 = dto.getMd5().toLowerCase(); createTmpPath(finalPath + md5); try (Stream\u0026lt;Path\u0026gt; pathStream = Files.list(Paths.get(tmpPath + md5 + \u0026#34;/\u0026#34;));) { byte[] reduce = pathStream .sorted((s1, s2) -\u0026gt; { int n1 = Integer.parseInt(s1.getFileName().toString().split(\u0026#34;\\\\.\u0026#34;, 0)[0]); int n2 = Integer.parseInt(s2.getFileName().toString().split(\u0026#34;\\\\.\u0026#34;, 0)[0]); return Integer.compare(n1, n2); }) .map(this::readByteByPath) .filter(Objects::nonNull) .reduce(new byte[]{}, this::addBytes); String s = DigestUtils.md5DigestAsHex(reduce); FileCopyUtils.copy(reduce, new File(finalPath + md5 + \u0026#34;/\u0026#34; + dto.getFileName())); deleteDir(tmpPath + md5); } catch (IOException e) { e.printStackTrace(); } return ResponseResult.createBySuccess(); } /** * 删除分片 * */ private void deleteDir(String path) { Path dir = Paths.get(path); try (Stream\u0026lt;Path\u0026gt; pathStream = Files.list(dir)) { pathStream.forEach(p -\u0026gt; { try { Files.delete(p); // 删除分片缓存信息 chunkMap.remove(p.toString()); } catch (IOException e) { e.printStackTrace(); } }); Files.delete(dir); } catch (IOException e) { e.printStackTrace(); } } /** * 读文件 * */ private byte[] readByteByPath(Path i) { try { return Files.readAllBytes(i); } catch (IOException e) { e.printStackTrace(); return null; } } /** * 合并文件 * */ public byte[] addBytes(byte[] data1, byte[] data2) { byte[] data3 = new byte[data1.length + data2.length]; System.arraycopy(data1, 0, data3, 0, data1.length); System.arraycopy(data2, 0, data3, data1.length, data2.length); return data3; } /** * 创建文件夹 * */ private void createTmpPath(String pathString) { Path path = Paths.get(pathString); // 并发 if (Files.exists(path)){ return; } synchronized (this) { if (Files.notExists(path)) { try { Files.createDirectory(path); } catch (IOException e) { e.printStackTrace(); throw new ServiceException(\u0026#34;创建失败\u0026#34;); } } } } @Data public static class UploadFileDTO { @ApiModelProperty(\u0026#34;文件MD5\u0026#34;) private String md5; @ApiModelProperty(\u0026#34;分片文件序号\u0026#34;) private Integer index; @ApiModelProperty(\u0026#34;分片文件\u0026#34;) private MultipartFile file; } @Data public static class MergeFileDTO { @ApiModelProperty(\u0026#34;文件MD5\u0026#34;) private String md5; @ApiModelProperty(\u0026#34;原文件名 带后缀\u0026#34;) private String fileName; } } demo用作生产时需要优化的点 1. 对接redis和mysql 分片上传的状态, 文件上传的状态, 文件的地址等信息, 存储在数据库中, 或redis缓存, 视情况而定\n2. 对接阿里云/天翼云等云对象存储服务 一般在项目中都是使用的第三方的对象催出服务, 需要对接一下, 一般也都有分片上传的api\n3. 断点续传 当我们把分片信息存储在数据库中的时候, 之后就可以通过md5 key(或自定义唯一key, 但前后端需要沟通统一), 来获取之前的分片上传状态\n4. 校验md5 基于后端不完全信任客户端的思想, 后端需要算出分片或大文件特征(前后端沟通统一特征的规则, eg第一个分片+最后一个分片)的md5, 与前端传的md5是否一致.. 等等之类的校验, 视情况而定\n5. 秒传 需要一个新的接口, 在分片上传之前从数据库获取整个大文件特征对应的md5 对应的文件上传状态\n完全无信息\n就是没有上传过, 需要分片上传\n一部分信息\n上传过一部分, 可做断点续传的前提\n整个大文件已上传\n秒传的前提判断\n6. 并发问题 分片上传一般为并发状态, 需要处理好代码的并发问题\n7. 分片规则 分片的大小规则是否由服务端来控制, 视情况而定\n8. 多线程合并文件 注意点: 文件需要顺序合并, 不能乱序\n思路:\n将文件序号, 和文件提取, 放在Pair中, 并排序\n1 2 3 List\u0026lt;Pair\u0026lt;Integer, byte[]\u0026gt;\u0026gt; pairs = pathStream .map(p -\u0026gt; Pair.of(Integer.parseInt(p.getFileName().toString().split(\u0026#34;\\\\.\u0026#34;, 0)[0]), readByteByPath(p))) .toList(); 利用stream的groupingBy和mapping, 对序号整除5分组, 分成一堆一堆的\n1 2 3 Map\u0026lt;Integer, List\u0026lt;byte[]\u0026gt;\u0026gt; collect = pairs.stream() .sorted(Comparator.comparingInt(Pair::getKey)) .collect(Collectors.groupingBy(p -\u0026gt; p.getKey() / 5, Collectors.mapping(Pair::getValue, Collectors.toList()))); 使用多线程, 每堆一个线程, 将每一堆合并\n方式一: 并行流\n1 2 3 4 5 pairs = joinPool.submit(() -\u0026gt; collect.entrySet().parallelStream() .map(entry -\u0026gt; Pair.of(entry.getKey(), entry.getValue().stream().reduce(new byte[]{}, this::addBytes))) .toList() ).get(); 方式二: CompletableFuture+自定义线程池\n1 2 3 4 pairs = collect.entrySet().stream() .map(en -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; mergeBytes(en), executorService)) .map(CompletableFuture::join) .collect(Collectors.toList()); 判断合并后list的大小, 如果还有很多, 则继续第二步, 否则写入文件(也就是已经合并完了, 只剩下一个)\n1 2 3 4 5 while (pairs.size() \u0026gt; 1) {...} FileCopyUtils.copy(pairs.get(0).getValue(), new File(finalPath + md5 + \u0026#34;/\u0026#34; + dto.getFileName())); deleteDir(tmpPath + md5); 方式一: 使用指定线程数的并行流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 /** * 合并文件 * * @param dto dto * @return {@link String} */ @PostMapping(\u0026#34;mergeFile\u0026#34;) public ResponseResult\u0026lt;?\u0026gt; mergeFile(@RequestBody MergeFileDTO dto) { String md5 = dto.getMd5().toLowerCase(); createTmpPath(finalPath + md5); ForkJoinPool joinPool = new ForkJoinPool(5); try (Stream\u0026lt;Path\u0026gt; pathStream = Files.list(Paths.get(tmpPath + md5 + \u0026#34;/\u0026#34;));) { List\u0026lt;Pair\u0026lt;Integer, byte[]\u0026gt;\u0026gt; pairs = pathStream .map(p -\u0026gt; Pair.of(Integer.parseInt(p.getFileName().toString().split(\u0026#34;\\\\.\u0026#34;, 0)[0]), readByteByPath(p))) .toList(); while (pairs.size() \u0026gt; 1) { Map\u0026lt;Integer, List\u0026lt;byte[]\u0026gt;\u0026gt; collect = pairs.stream() .sorted(Comparator.comparingInt(Pair::getKey)) .collect(Collectors.groupingBy(p -\u0026gt; p.getKey() / 5, Collectors.mapping(Pair::getValue, Collectors.toList()))); pairs = joinPool.submit(() -\u0026gt; collect.entrySet().parallelStream() .map(entry -\u0026gt; Pair.of(entry.getKey(), entry.getValue().stream().reduce(new byte[]{}, this::addBytes))) .toList() ).get(); } FileCopyUtils.copy(pairs.get(0).getValue(), new File(finalPath + md5 + \u0026#34;/\u0026#34; + dto.getFileName())); deleteDir(tmpPath + md5); } catch (Exception e) { e.printStackTrace(); } return ResponseResult.createBySuccess(); } 指定线程数\n1 ForkJoinPool joinPool = new ForkJoinPool(5); 提交\n1 2 3 4 5 pairs = joinPool.submit(() -\u0026gt; collect.entrySet().parallelStream() .map(entry -\u0026gt; Pair.of(entry.getKey(), entry.getValue().stream().reduce(new byte[]{}, this::addBytes))) .toList() ).get(); 方式二: CompletableFuture+自定义线程池 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @PostMapping(\u0026#34;mergeFile\u0026#34;) public ResponseResult\u0026lt;?\u0026gt; mergeFile(@RequestBody MergeFileDTO dto) { String md5 = dto.getMd5().toLowerCase(); createTmpPath(finalPath + md5); ExecutorService executorService = Executors.newFixedThreadPool(5); try (Stream\u0026lt;Path\u0026gt; pathStream = Files.list(Paths.get(tmpPath + md5 + \u0026#34;/\u0026#34;));) { List\u0026lt;Pair\u0026lt;Integer, byte[]\u0026gt;\u0026gt; pairs = pathStream .map(p -\u0026gt; Pair.of(Integer.parseInt(p.getFileName().toString().split(\u0026#34;\\\\.\u0026#34;, 0)[0]), readByteByPath(p))) .toList(); while (pairs.size() \u0026gt; 1) { Map\u0026lt;Integer, List\u0026lt;byte[]\u0026gt;\u0026gt; collect = pairs.stream() .sorted(Comparator.comparingInt(Pair::getKey)) .collect(Collectors.groupingBy(p -\u0026gt; p.getKey() / 5, Collectors.mapping(Pair::getValue, Collectors.toList()))); pairs = collect.entrySet().stream() .map(en -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; mergeBytes(en), executorService)) .map(CompletableFuture::join) .collect(Collectors.toList()); } FileCopyUtils.copy(pairs.get(0).getValue(), new File(finalPath + md5 + \u0026#34;/\u0026#34; + dto.getFileName())); deleteDir(tmpPath + md5); } catch (Exception e) { e.printStackTrace(); } return ResponseResult.createBySuccess(); } public Pair\u0026lt;Integer, byte[]\u0026gt; mergeBytes(Map.Entry\u0026lt;Integer, List\u0026lt;byte[]\u0026gt;\u0026gt; entry) { return Pair.of(entry.getKey(), entry.getValue().stream().reduce(new byte[]{}, this::addBytes)); } 自定义线程池, 或使用new Executor(\u0026hellip;\u0026hellip;);\n1 ExecutorService executorService = Executors.newFixedThreadPool(5); 使用CompletableFuture\n1 2 3 4 pairs = collect.entrySet().stream() .map(en -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; mergeBytes(en), executorService)) .map(CompletableFuture::join) .collect(Collectors.toList()); 优化点 while中的条件可以改大一点, 也就是实现分情况开启多线程, 当文件数足够多的时候开启多线程, 否则直接主线程合并, 这样可以避免线程切换的开销, 视情况而定.\n","permalink":"https://habyss.github.io/posts/tech/big_file_upload/","summary":"简单demo和多线程合并文件优化","title":"大文件分片上传"},{"content":"💡 不可以对查询参数加解密\n💡 不会修改原对象数据\n💡 对于手写sql需要特殊指定\n💡 对于非sql的CRUD可自动加解密\n1. 非sql查询 — 数据库实体类 1 2 3 4 @TableName(value = \u0026#34;t_user_auth\u0026#34;, autoResultMap = true) @TableField(typeHandler = CryptHandler.class) private String cardNo; 2. 非sql查询 — typrHandler实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Slf4j public class CryptHandler extends BaseTypeHandler\u0026lt;String\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { log.warn(parameter); ps.setString(i, \u0026#34;DESUtil.encrypt(parameter)\u0026#34;); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { String string = rs.getString(columnName); log.warn(string); return \u0026#34;DESUtil.decrypt(string)\u0026#34;; } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { String string = rs.getString(columnIndex); log.warn(string); return \u0026#34;DESUtil.decrypt(string)\u0026#34;; } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { String string = cs.getString(columnIndex); log.warn(string); return \u0026#34;DESUtil.decrypt(string)\u0026#34;; } } 3. sql查询 — 其他复杂查询 1 2 3 4 \u0026lt;resultMap id=\u0026#34;filterListMap\u0026#34; type=\u0026#34;com.somenet.response.patient.MPatientFilterResponse\u0026#34;\u0026gt; \u0026lt;result column=\u0026#34;card_no\u0026#34; property=\u0026#34;cardNo\u0026#34; typeHandler=\u0026#34;com.somenet.handler.crypt.CryptHandler\u0026#34; /\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;filterList\u0026#34; resultMap=\u0026#34;filterListMap\u0026#34; \u0026gt; ","permalink":"https://habyss.github.io/posts/tech/mybatis_plus_typehandler/","summary":"💡 不可以对查询参数加解密 💡 不会修改原对象数据 💡 对于手写sql需要特殊指定 💡 对于非sql的CRUD可自动加解密 1. 非sql查询 — 数据库实体类 1 2","title":"基于mybatis-plus typeHandler 加解密简单实现"},{"content":"思路 表结构:\n1 2 3 4 5 6 7 8 9 create table scar_test.h_sort_table ( id bigint auto_increment primary key, `sort` bigint not null, update_time datetime null, create_time datetime null ) comment \u0026#39;测试\u0026#39;; sort为序号, 初始间隔为2^10=1024, 类型为long\n新增数据时, 需要先查出最大sort, 然后加上2^10=1024\n前端传参数据:\n1 2 3 4 5 6 7 8 { \u0026#34;currentId\u0026#34;: 23, \u0026#34;currentIndex\u0026#34;: 8, \u0026#34;preSort\u0026#34;: 21505, \u0026#34;nextSort\u0026#34;: 21504, \u0026#34;pageNum\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 10 } 当拖拽到第一个元素时, preSort为null\n当拖拽到最后一个元素时, nextSort为null\n正常排序: currentSort = (preSort - nextSort) / 2 + nextSort\n重新排序: 将此页数据从数据库全部查出, 计算平均间隔, 批量更新\n可能情况:\n(preSort - nextSort) / 2 \u0026lt;= 0 此时前后元素之间已经没有间隔可以插入当前元素, 需要*[重新排序]*\n(preSort - nextSort) / 2 \u0026gt; 0\n此时前后元素之间有间隔, 可以*[正常排序]*\npreSort == null\n此时不知道上一页的最后一个元素的sort, 直接*[重新排序]*\nnextSort == null\n此时不知道下一页的最后一个元素的sort, 直接*[重新排序]*\n代码实现 lombok项目根路径已配置默认全局配置, lombok.config\n1 2 3 config.stopBubbling=true lombok.equalsAndHashCode.callSuper=call lombok.accessors.chain=true 前后端交互入参 SortParam 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Data public class SortParam { // 当前元素id private Long currentId; // 当前元素在list中的index private Integer currentIndex; // 前一个元素的sort 拖拽到第一个时为null private Long preSort; // 后一个元素的sort 拖拽到最后一个时为null private Long nextSort; // 分页参数 private Integer pageNum = 10; private Integer pageSize = 10; /** * 需要重新排序 * * @return boolean */ public boolean needReSort() { return preSort == null || nextSort == null || (preSort - nextSort) / 2 \u0026lt;= 0; } /** * 计算当前序号 * * @return {@link Long} */ public Long calcCurrentSort() { return (preSort - nextSort) / 2 + nextSort; } } eg:\n1 2 3 4 5 6 7 8 { \u0026#34;currentId\u0026#34;: 23, \u0026#34;currentIndex\u0026#34;: 8, \u0026#34;preSort\u0026#34;: 21505, \u0026#34;nextSort\u0026#34;: 21504, \u0026#34;pageNum\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 10 } vo 1 2 3 4 5 @Data public class SortDataVo { private Long id; private Long sort; } entity 1 2 3 4 5 6 7 8 9 10 @Getter @Setter @TableName(\u0026#34;h_sort_table\u0026#34;) @ApiModel(value = \u0026#34;SortTable对象\u0026#34;, description = \u0026#34;测试\u0026#34;) public class SortTable extends BaseEntity { private static final long serialVersionUID = 1L; private Long sort; } base 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Data public class BaseEntity { @ApiModelProperty(\u0026#34;ID\u0026#34;) @TableId(value = \u0026#34;id\u0026#34;, type = IdType.AUTO) private Long id; @ApiModelProperty(\u0026#34;更新时间\u0026#34;) @TableField(fill = FieldFill.INSERT_UPDATE) private LocalDateTime updateTime; @ApiModelProperty(\u0026#34;创建时间\u0026#34;) @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; @ApiModelProperty(\u0026#34;保留|删除\u0026#34;) @TableLogic private Boolean deleted; } controller代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Slf4j @RestController @RequestMapping(\u0026#34;dict\u0026#34;) public class DictController { @Resource private ISortTableService sortTableService; /** * 排序 * * @param sortParam 排序参数 * @return {@link ResponseResult}\u0026lt;{@link PageVo}\u0026lt;{@link SortDataVo}\u0026gt;\u0026gt; */ @PostMapping(\u0026#34;sort\u0026#34;) public ResponseResult\u0026lt;PageVo\u0026lt;SortDataVo\u0026gt;\u0026gt; sort(@RequestBody SortParam sortParam) { if (sortParam.needReSort()) { sortTableService.reSort(sortParam); }else { sortTableService.normalSort(sortParam); } PageVo\u0026lt;SortDataVo\u0026gt; pageVo = sortTableService.pageList(sortParam); return ResponseResult.createBySuccess(pageVo); } /** * 测试初始化数据 * * @return {@link ResponseResult}\u0026lt;{@link ?}\u0026gt; */ @PostMapping(\u0026#34;init\u0026#34;) public ResponseResult\u0026lt;?\u0026gt; init() { sortTableService.init(); return ResponseResult.createBySuccess(); } } service代码 service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public interface ISortTableService extends IService\u0026lt;SortTable\u0026gt; { /** * 重新排序 * * @param sortParam 排序参数 */ void reSort(SortParam sortParam); /** * 正常排序 * * @param sortParam 排序参数 */ void normalSort(SortParam sortParam); /** * 分页查询 * * @param sortParam 排序参数 */ PageVo\u0026lt;SortDataVo\u0026gt; pageList(SortParam sortParam); void init(); } serviceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @Service public class SortTableServiceImpl extends ServiceImpl\u0026lt;SortTableMapper, SortTable\u0026gt; implements ISortTableService { @Resource SortTableMapper sortTableMapper; @Override public void reSort(SortParam sortParam) { // 重排时获取当前页数据 List\u0026lt;SortDataVo\u0026gt; records = pageList(sortParam).getRecords(); int size = records.size(); Long maxSort = records.get(0).getSort(); Long minSort = records.get(size - 1).getSort(); // 计算重排间隔 long intervalSort = (maxSort - minSort) / (size - 1); // 先移当前元素 records.removeIf(r -\u0026gt; Objects.equals(r.getId(), sortParam.getCurrentId())); // 根据入参的index 放置当前元素 records.add(sortParam.getCurrentIndex(), new SortDataVo().setId(sortParam.getCurrentId())); // 重排 重新分配sort for (SortDataVo record : records) { record.setSort(maxSort); maxSort -= intervalSort; } // 组装数据 批量更新 List\u0026lt;SortTable\u0026gt; sortTables = MapperUtil.mapAsList(records, SortTable.class); this.updateBatchById(sortTables); } @Override public void normalSort(SortParam sortParam) { // 计算当前元素sort Long currentIndex = sortParam.calcCurrentSort(); SortTable sortTable = new SortTable().setSort(currentIndex); sortTable.setId(sortParam.getCurrentId()); sortTableMapper.updateById(sortTable); } @Override public PageVo\u0026lt;SortDataVo\u0026gt; pageList(SortParam sortParam) { Page\u0026lt;SortTable\u0026gt; page = PageHelper.startPage(sortParam) .doSelectPage(() -\u0026gt; sortTableMapper.selectList( Wrappers.\u0026lt;SortTable\u0026gt;lambdaQuery().orderByDesc(SortTable::getSort) ) ); return PageUtil.convertPage(page, SortDataVo.class); } @Override public void init() { long intervalSort = 1024; AtomicLong init = new AtomicLong(); List\u0026lt;SortTable\u0026gt; sortTables = IntStream.rangeClosed(1, 30) .mapToObj((r -\u0026gt; new SortTable().setSort(init.addAndGet(intervalSort)))) .toList(); this.saveBatch(sortTables); } } 工具类 MapperUtil, 对BeanUtils简单封装\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class MapperUtil { public static \u0026lt;T, S\u0026gt; List\u0026lt;T\u0026gt; mapAsList(Collection\u0026lt;S\u0026gt; source, Class\u0026lt;T\u0026gt; target) { return source.stream().map(one -\u0026gt; map(one, target)).collect(Collectors.toList()); } public static \u0026lt;T, S\u0026gt; T map(S source, Class\u0026lt;T\u0026gt; target) { if (source == null) { return null; } T result; try { result = target.getDeclaredConstructor().newInstance(); } catch (InstantiationException | IllegalAccessException | InvocationTargetException | NoSuchMethodException ex) { throw new RuntimeException(ex); } BeanUtils.copyProperties(source, result); return result; } } PageUtil, 分页结果简单转换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class PageUtil { public static \u0026lt;T\u0026gt; PageVo\u0026lt;T\u0026gt; convertPage(Page\u0026lt;T\u0026gt; page) { return new PageVo\u0026lt;\u0026gt;(page.getPageNum(), page.getPageSize(), page.getTotal(), page.getResult()); } public static \u0026lt;V, T\u0026gt; PageVo\u0026lt;V\u0026gt; convertPage(Page\u0026lt;T\u0026gt; page, Class\u0026lt;V\u0026gt; vClass) { List\u0026lt;V\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); if (!CollectionUtils.isEmpty(page.getResult())) { list = MapperUtil.mapAsList(page.getResult(), vClass); } return new PageVo\u0026lt;\u0026gt;(page.getPageNum(), page.getPageSize(), page.getTotal(), list); } } 另外 如果重新排序的的前置计算前端来做的话, 可以省去后端去数据库查询当页数据, 因为前端已经有了此页的所有数据.\n当时并没有高并发场景, 用户排序仅仅只能排自己的数据, 也就不涉及并发下的排序\n","permalink":"https://habyss.github.io/posts/tech/%E6%8B%96%E6%8B%BD%E6%8E%92%E5%BA%8F/","summary":"思路 表结构: 1 2 3 4 5 6 7 8 9 create table scar_test.h_sort_table ( id bigint auto_increment primary key, `sort` bigint not null, update_time datetime null, create_time datetime null ) comment \u0026#39;测试\u0026#39;; sort为序号, 初始间隔为2^10=102","title":"拖拽排序实现"},{"content":"一、超时优化 OpenFeign 底层内置了 Ribbon 框架，并且使用了 Ribbon 的请求连接超时时间和请求处理超时时间作为其超时时间，而 Ribbon 默认的请求连接超时时间和请求处理超时时间都是 1s, 当我们使用 OpenFeign 调用了服务接口超过 1s，就会出现错误.\n因为 1s 确实太短了，因此我们需要手动设置 OpenFeign 的超时时间以保证它能正确的处理业务。OpenFeign 的超时时间有以下两种更改方法：\n通过修改 Ribbon 的超时时间，被动的修改 OpenFeign 的超时时间。 直接修改 OpenFeign 的超时时间(推荐使用)。 1、设置Ribbon超时时间(未验证) 在项目配置文件 application.yml 中添加以下配置：\n1 2 3 ribbon: ReadTimeout: 5000 # 请求连接的超时时间 ConnectionTimeout: 10000 # 请求处理的超时时间 2、设置OpenFeign超时时间 在项目配置文件 application.yml 中添加以下配置：\n1 2 3 4 5 6 feign: client: config: default: connect-timeout: 2000 read-timeout: 5000 推荐使用此方式来设置 OpenFeign 的超时时间，因为这样的配置语义更明确。\n二、请求连接优化 OpenFeign 底层通信组件默认使用 JDK 自带的 URLConnection 对象进行 HTTP 请求的，因为没有使用连接池，所以性能不是很好。我们可以将 OpenFeign 的通讯组件，手动替换成像 Apache HttpClient 或 OKHttp 这样的专用通信组件，这些的专用通信组件自带连接池可以更好地对 HTTP 连接对象进行重用与管理，同时也能大大的提升 HTTP 请求的效率。接下来以 Apache HttpClient 为例，演示一下专用通讯组件的使用。\n1、引入Apache HttpClient依赖 在项目的依赖管理文件 pom.xml 中添加以下配置：\n1 2 3 4 5 6 7 8 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2、开启Apache HttpClient使用 启动 Apache HttpClient 组件，在项目配置文件 application.yml 中添加以下配置,\n1 2 3 feign: httpclient: enabled: true 三、数据压缩 OpenFeign 默认不会开启数据压缩功能，但我们可以手动的开启它的 Gzip 压缩功能，这样可以极大的提高宽带利用率和加速数据的传输速度，在项目配置文件 application.yml 中添加以下配置：\n1 2 3 4 5 6 7 8 9 feign: compression: request: enabled: true # 默认就是这些类型 # mime-types: text/xml, application/xml, application/json min-request-size: 1024 response: enabled: true PS：如果服务消费端的 CPU 资源比较紧张的话，建议不要开启数据的压缩功能，因为数据压缩和解压都需要消耗 CPU 的资源，这样反而会给 CPU 增加了额外的负担，也会导致系统性能降低。\n四、负载均衡优化 OpenFeign 底层使用的是 Ribbon 做负载均衡的，查看源码我们可以看到它默认的负载均衡策略是轮询策略\n然而除了轮询策略之外，我们还有其他 6 种内置的负载均衡策略可以选择，这些负载均衡策略如下：\n**权重策略：**WeightedResponseTimeRule，根据每个服务提供者的响应时间分配一个权重，响应时间越长，权重越小，被选中的可能性也就越低。它的实现原理是，刚开始使用轮询策略并开启一个计时器，每一段时间收集一次所有服务提供者的平均响应时间，然后再给每个服务提供者附上一个权重，权重越高被选中的概率也越大。 **最小连接数策略：**BestAvailableRule，也叫最小并发数策略，它是遍历服务提供者列表，选取连接数最小的⼀个服务实例。如果有相同的最小连接数，那么会调用轮询策略进行选取。 **区域敏感策略：**ZoneAvoidanceRule，根据服务所在区域(zone)的性能和服务的可用性来选择服务实例，在没有区域的环境下，该策略和轮询策略类似。 **可用敏感性策略：**AvailabilityFilteringRule，先过滤掉非健康的服务实例，然后再选择连接数较小的服务实例。 **随机策略：**RandomRule，从服务提供者的列表中随机选择一个服务实例。 **重试策略：**RetryRule，按照轮询策略来获取服务，如果获取的服务实例为 null 或已经失效，则在指定的时间之内不断地进行重试来获取服务，如果超过指定时间依然没获取到服务实例则返回 null。 出于性能方面的考虑，我们可以选择用权重策略或区域敏感策略来替代轮询策略，因为这样的执行效率最高。\n五、日志级别优化 OpenFeign 提供了日志增强功能，它的日志级别有以下几个：\n**NONE：**默认的，不显示任何日志。 **BASIC：**仅记录请求方法、URL、响应状态码及执行时间。 **HEADERS：**除了 BASIC 中定义的信息之外，还有请求和响应的头信息。 **FULL：**除了 HEADERS 中定义的信息之外，还有请求和响应的正文及元数据。 我们可以通过配置文件来设置日志级别，配置信息如下：\n1 2 3 4 5 6 7 8 9 10 @Configuration public class OpenfeignConfig { @Bean Logger.Level feignLoggerLevel(){ return Logger.Level.FULL;//FULL是详细日志 } } logging: level: cn.xxx.service: debug 其中 cn.xxx.service 为 OpenFeign 接口所在的包名。虽然 OpenFeign 默认是不输出任何日志，但在开发阶段可能会被修改，因此在生产环境中，我们应仔细检查并设置合理的日志级别，以提高 OpenFeign 的运行效率。\n总结 OpenFeign 是 Spring 官方推出的一种声明式服务调用和负载均衡组件，在生产环境中我们可以通过以下配置来优化 OpenFeign 的运行：\n修改 OpenFeign 的超时时间，让 OpenFeign 能够正确的处理业务。 通过配置专用的通信组件 Apache HttpClient 或 OKHttp，让 OpenFeign 可以更好地对 HTTP 连接对象进行重用和管理，以提高其性能。 开启数据压缩功能，可以提高宽带利用率和加速数据传输速度。 使用合适的负载均衡策略来替换默认的轮询负载均衡策略，已获得更好的执行效率。 检查生成环境中 OpenFeign 的日志级别，选择合适的日志输出级别，防止无效的日志输出。 ","permalink":"https://habyss.github.io/posts/tech/openfeign/","summary":"一、超时优化 OpenFeign 底层内置了 Ribbon 框架，并且使用了 Ribbon 的请求连接超时时间和请求处理超时时间作为其超时时间，而 Ribbon 默认的请求连接超时时间和请求处理超时时间","title":"OpenFeign优化"},{"content":"需求 首页需要展示最近七天的一些指标的统计图, 而数据库中实在不同的地方存储的, 且日期并非连续有数据.\n数据库 常规使用groupby分组\n1 2 3 4 5 select count(id) countNum, date_format(create_time, \u0026#39;%Y-%m-%d\u0026#39;) date from table where xxx = #{xxx} and create_time \u0026lt;![CDATA[\u0026gt;=]]\u0026gt; #{start} group by date java代码处理生成连续日期流 1 2 3 4 5 6 7 8 9 10 11 12 13 // 获取数据库数据转map Map\u0026lt;LocalDate, Long\u0026gt; xxxMap = xxxService.countInfo(parma, start).stream() .collect(Collectors.toMap(PatientCountInfo::getDate, PatientCountInfo::getRegistryCount)); Map\u0026lt;LocalDate, Long\u0026gt; yyyMap = yyyService.countInfo(parma, start).stream() .collect(Collectors.toMap(PatientCountInfo::getDate, PatientCountInfo::getConsultationCount)); // 组装相应日期数据 List\u0026lt;ResultVo\u0026gt; result = start.datesUntil(end.plusDays(1)) .map(d -\u0026gt; new ResultVo() .setDate(d) .setXxxCount(xxxMap.getOrDefault(d, 0L)) .setYyyCount(yyyMap.getOrDefault(d, 0L)) ) .toList(); 主要是LocalDate中的public Stream\u0026lt;LocalDate\u0026gt; datesUntil(LocalDate endExclusive)方法可以生成连续日期流, 大大简化了生成连续日期的开发.\n","permalink":"https://habyss.github.io/posts/tech/%E8%BF%9E%E7%BB%AD%E6%97%A5%E6%9C%9F%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE/","summary":"需求 首页需要展示最近七天的一些指标的统计图, 而数据库中实在不同的地方存储的, 且日期并非连续有数据. 数据库 常规使用groupby分组 1 2 3 4 5","title":"连续日期统计数据/日期无数据填充"},{"content":"pom 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;dependencies\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-ratelimiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-all\u0026lt;/artifactId\u0026gt; version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-spring-boot2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 想使用resilience4j的注解功能，需要引入aop --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 配置 您可以在springboot中配置断路器、重试、限流器、隔离、线程池隔离和限时器实例。使用application.yml进行配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 resilience4j.circuitbreaker: instances: backendA: registerHealthIndicator: true slidingWindowSize: 100 backendB: # 健康监控开启 registerHealthIndicator: true # 若COUNT_BASED，10次调用中有50%失败（即5次）打开熔断断路器； # 若TIME_BASED，在10秒内（sliding-window-size）100%（slow-call-rate-threshold）的请求超过2秒（slow-call-duration-threshold）打开断路器。 slidingWindowSize: 10 # 运行断路器在HALF_OPEN状态下时进行3次调用，如果故障或慢速调用仍然高于阈值，断路器再次进入打开状态。 permittedNumberOfCallsInHalfOpenState: 3 # 滑动窗口期类型 次数COUNT_BASED 时间TIME_BASED 默认COUNT_BASED。 slidingWindowType: TIME_BASED # 每个滑动窗口期 最少20次请求后生效 minimumNumberOfCalls: 20 # 一旦断路器是打开状态，它会拒绝请求50秒钟，然后转入半开状态。 waitDurationInOpenState: 50s # 50%的失败请求, 开启断路 failureRateThreshold: 50 eventConsumerBufferSize: 10 recordFailurePredicate: io.github.robwin.exception.RecordFailurePredicate resilience4j.retry: instances: backendA: maxRetryAttempts: 3 waitDuration: 10s enableExponentialBackoff: true exponentialBackoffMultiplier: 2 retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.io.IOException ignoreExceptions: - io.github.robwin.exception.BusinessException backendB: maxRetryAttempts: 3 waitDuration: 10s retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.io.IOException ignoreExceptions: - io.github.robwin.exception.BusinessException resilience4j.bulkhead: instances: backendA: maxConcurrentCalls: 10 backendB: maxWaitDuration: 10ms maxConcurrentCalls: 20 resilience4j.thread-pool-bulkhead: instances: backendC: maxThreadPoolSize: 1 coreThreadPoolSize: 1 queueCapacity: 1 resilience4j.ratelimiter: instances: backendA: # 限流10个 limitForPeriod: 10 # 每秒 limitRefreshPeriod: 1s # 被阻塞的线程最长等待时间, 超时会异常 timeoutDuration: 0 registerHealthIndicator: true # 被阻塞最大线程数量, 超出会异常 eventConsumerBufferSize: 100 backendB: limitForPeriod: 6 limitRefreshPeriod: 500ms timeoutDuration: 3s resilience4j.timelimiter: instances: backendA: timeoutDuration: 2s cancelRunningFuture: true backendB: timeoutDuration: 1s cancelRunningFuture: false 还可以覆盖默认配置，定义共享配置并在springboot中覆盖它们应用程序application.yml 配置文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 resilience4j.circuitbreaker: configs: default: slidingWindowSize: 100 permittedNumberOfCallsInHalfOpenState: 10 waitDurationInOpenState: 10000 failureRateThreshold: 60 eventConsumerBufferSize: 10 registerHealthIndicator: true someShared: slidingWindowSize: 50 permittedNumberOfCallsInHalfOpenState: 10 instances: backendA: baseConfig: default waitDurationInOpenState: 5000 backendB: baseConfig: someShared 通过代码覆盖默认配置 您还可以通过对特定实例名称使用Customizer来覆盖特定断路器、隔离、重试、限流器或限时器实例的配置。下面的示例演示了如何在配置的断路器backendA对上面的YAML文件进行覆盖。\n1 2 3 4 5 @Bean public CircuitBreakerConfigCustomizer testCustomizer() { return CircuitBreakerConfigCustomizer .of(\u0026#34;backendA\u0026#34;, builder -\u0026gt; builder.slidingWindowSize(100)); } Resilience4j有自己的customizer类型，可以按上图所示使用：\nResilienc4j类型 自定义类 Circuit breaker CircuitBreakerConfigCustomizer Retry RetryConfigCustomizer Rate limiter RateLimiterConfigCustomizer Bulkhead BulkheadConfigCustomizer ThreadPoolBulkhead ThreadPoolBulkheadConfigCustomizer Time Limiter TimeLimiterConfigCustomizer 切面的顺序 Resilience4j的切面执行顺序：\n1 Retry ( CircuitBreaker ( RateLimiter ( TimeLimiter ( Bulkhead ( Function ) ) ) ) ) 所以Retry 是最后执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @CircuitBreaker(name = BACKEND, fallbackMethod = \u0026#34;fallback\u0026#34;) @RateLimiter(name = BACKEND) @Bulkhead(name = BACKEND) @Retry(name = BACKEND, fallbackMethod = \u0026#34;fallback\u0026#34;) @TimeLimiter(name = BACKEND) public Mono\u0026lt;String\u0026gt; method(String param1) { return Mono.error(new NumberFormatException()); } private Mono\u0026lt;String\u0026gt; fallback(String param1, IllegalArgumentException e) { return Mono.just(\u0026#34;test\u0026#34;); } private Mono\u0026lt;String\u0026gt; fallback(String param1, RuntimeException e) { return Mono.just(\u0026#34;test\u0026#34;); } ","permalink":"https://habyss.github.io/posts/tech/resilience4j_%E7%86%94%E6%96%AD/","summary":"pom 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;dependencies\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-ratelimiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- resilience4j 按需引入 或 all--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-all\u0026lt;/artifactId\u0026gt; version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.resilience4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;resilience4j-spring-boot2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${resilience4jVersion}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 想使用resilienc","title":"resilience4j-spring-boot2 熔断"},{"content":" 最近看到视频流的东西, 浅浅看了一下, demo记录\nffmpeg视频切片 1 ffmpeg -i test.mp4 -c copy -f hls -hls_list_size 0 -hls_time 10 -hls_segment_filename \u0026#39;file%03d.ts\u0026#39; out.m3u8 命令简单解释:\n1.ffmpeg切片命令，以H264和AAC的形式对视频进行输出\n1 ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls output.m3u8 2.ffmpeg转化成HLS时附带的指令\n1 ffmpeg -i output.mp4 -c:v libx264 -c:a aac -strict -2 -f hls -hls_list_size 0 -hls_time 5 output1.m3u8 默认的每片长度为 2 秒，m3u8 文件中默认只保存最新的 5 条片的信息，导致最后播放的时候只能播最后的一小部分（直播的时候特别注意）\n-hls_time n 设置每片的长度，默认值为 2，单位为秒。-hls_list_size n 设置播放列表保存的最多条目，设置为 0 会保存有所片信息，默认值为5\n-hls_wrap n 设置多少片之后开始覆盖，如果设置为0则不会覆盖，默认值为0。这个选项能够避免在磁盘上存储过多的 片，而且能够限制写入磁盘的最多的片的数量\n-hls_start_number n 设置播放列表中 sequence number 的值为 number，默认值为 0\n注意：播放列表的 sequence number 对每个 segment 来说都必须是唯一的，而且它不能和片的文件名（当使用 wrap 选项时，文件名有可能会重复使用）混淆\n-c:v 将处理后的流拷贝\n-c copy [命令简写]copy流\n后端demo 简单提供接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @GetMapping(\u0026#34;v/{fileName}\u0026#34;) public void video(@PathVariable String fileName, HttpServletResponse response) throws IOException { byte[] bytes = readByteByPath(Paths.get(\u0026#34;E:/test/\u0026#34; + fileName)); response.getOutputStream().write(Objects.requireNonNull(bytes)); } private byte[] readByteByPath(Path i) { try { return Files.readAllBytes(i); } catch (IOException e) { e.printStackTrace(); return null; } } 前端demo hls.js 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hls.js demo - basic usage\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script src=\u0026#34;./dist/hls.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;center\u0026gt; \u0026lt;h1\u0026gt;Hls.js demo - basic usage\u0026lt;/h1\u0026gt; \u0026lt;video height=\u0026#34;600\u0026#34; id=\u0026#34;video\u0026#34; controls\u0026gt;\u0026lt;/video\u0026gt; \u0026lt;/center\u0026gt; \u0026lt;script\u0026gt; var video = document.getElementById(\u0026#39;video\u0026#39;); if (Hls.isSupported()) { var hls = new Hls({ debug: true, }); hls.loadSource(\u0026#39;http://localhost:8080/v/out.m3u8\u0026#39;); hls.attachMedia(video); hls.on(Hls.Events.MEDIA_ATTACHED, function () { video.muted = true; video.play(); }); } // hls.js is not supported on platforms that do not have Media Source Extensions (MSE) enabled. // When the browser has built-in HLS support (check using `canPlayType`), we can provide an HLS manifest (i.e. .m3u8 URL) directly to the video element through the `src` property. // This is using the built-in support of the plain video element, without using hls.js. // else if (video.canPlayType(\u0026#39;application/vnd.apple.mpegurl\u0026#39;)) { // video.src = \u0026#39;http://localhost:8080/v/out.m3u8\u0026#39;; // video.addEventListener(\u0026#39;canplay\u0026#39;, function () { // video.play(); // }); // } \u0026lt;/script\u0026gt; \u0026lt;!-- injected in netlify post processing step --\u0026gt; \u0026lt;div style=\u0026#34;position: absolute; top: 5px; right: 5px;\u0026#34;\u0026gt; \u0026lt;a rel=\u0026#34;noopener\u0026#34; href=\u0026#34;https://www.netlify.com\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;\u0026lt;img src=\u0026#34;https://www.netlify.com/img/global/badges/netlify-color-accent.svg\u0026#34; /\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","permalink":"https://habyss.github.io/posts/tech/hls_ts_m3u8_demo/","summary":"最近看到视频流的东西, 浅浅看了一下, demo记录 ffmpeg视频切片 1 ffmpeg -i test.mp4 -c copy -f hls -hls_list_size 0 -hls_time 10 -hls_segment_filename \u0026#39;file%03d.ts\u0026#39; out.m3u8 命令简单解释: 1.ffmpeg切片命令，以","title":"hls ts m3u8 ffmpeg 前后端视频流demo"},{"content":"需求 需要模糊查询文章的标题\n探索 like 先测试一下300w数据量的耗时\n1 2 3 4 5 6 7 8 9 10 11 \u0026gt; select count(1) from t_banner 1 row retrieved starting from 1 in 160 ms (execution: 136 ms, fetching: 24 ms) 一共3114023条数据 \u0026gt; select * from t_banner where banner_title = \u0026#39;title523521end\u0026#39; 2 rows retrieved starting from 1 in 35 ms (execution: 7 ms, fetching: 28 ms) \u0026gt; select * from t_banner where banner_title like \u0026#39;%523521%\u0026#39; 3 rows retrieved starting from 1 in 1 s 428 ms (execution: 1 s 410 ms, fetching: 18 ms) \u0026gt; select * from t_banner where banner_title like \u0026#39;title523521%\u0026#39; 2 rows retrieved starting from 1 in 42 ms (execution: 8 ms, fetching: 34 ms) \u0026gt; select * from t_banner where banner_title like \u0026#39;%523521end\u0026#39; 3 rows retrieved starting from 1 in 1 s 432 ms (execution: 1 s 409 ms, fetching: 23 ms) 由上可以看出\n加索引的情况下where banner_title = 'title523521end' 和 where banner_title like 'title523521%'是走索引的, 耗时个位数毫秒\n而where banner_title like '%523521%'和where banner_title like '%523521end'耗时1.5秒,是不走索引的, 也就是索引失效, 1.5s在项目中已经很不能接受了.\nfulltext 先使用 ngram分词器 创建全文索引\n1 create fulltext index f_banner_tile on t_banner (banner_title) with parser ngram; 300w的数据, 字段长度在14-16, 耗时6min6 m 11 s 156 ms\nboolean模式 执行查询语法\n1 2 3 select * from t_banner where match(banner_title) against(\u0026#39;235213\u0026#39; in boolean mode); 执行结果\n1 2 3 4 \u0026gt; select * from t_banner where match(banner_title) against(\u0026#39;235213\u0026#39; in boolean mode) 3 rows retrieved starting from 1 in 9 s 329 ms (execution: 9 s 305 ms, fetching: 24 ms) 耗时达到惊人的9s, 比like的1.5s多得多..\nnatural模式 执行查询语法\n1 2 3 select * from t_banner where match(banner_title) against(\u0026#39;235213\u0026#39; in natural language mode) 执行结果\n1 2 3 4 \u0026gt; select * from t_banner where match(banner_title) against(\u0026#39;235213\u0026#39; in natural language mode) 740,887 rows retrieved starting from 1 in 16 s 798 ms (execution: 801 ms, fetching: 15 s 997 ms) 可以看到耗时800ms, 但是匹配的精准度也太差了\u0026hellip;一共匹配的3条数据, 硬生生匹配了74w\n总结 全文索引的确对模糊查询有效, 但是占用空间是大量的, 所以个人认为更加适用于长度比较短的字段, 但是他的匹配的精准度极差,而且它的分词逻辑并不像es的ik分词器那么合理.\n自MySQL5.7.6版起，MySQL将ngram全文解析器作为内置的服务器插件, 支持用于InnoDB和MyISAM存储引擎的ngram全文解析器。\n根据定义，ngram是来自文本序列的多个字符的连续序列。 ngram全文解析器的主要功能是将文本序列标记为n个字符的连续序列。\n以下说明了ngram全文解析器如何标记不同值n的文本序列：\n1 2 3 4 5 n = 1: \u0026#39;m\u0026#39;,\u0026#39;y\u0026#39;,\u0026#39;s\u0026#39;,\u0026#39;q\u0026#39;,\u0026#39;l\u0026#39; n = 2: \u0026#39;my\u0026#39;, \u0026#39;ys\u0026#39;, \u0026#39;sq\u0026#39;,\u0026#39;ql\u0026#39; n = 3: \u0026#39;mys\u0026#39;, \u0026#39;ysq\u0026#39;, \u0026#39;sql\u0026#39; n = 4: \u0026#39;mysq\u0026#39;, \u0026#39;ysql\u0026#39; n = 5: \u0026#39;mysql\u0026#39; 1 2 3 4 N=1 : \u0026#39;齿\u0026#39;, \u0026#39;轮\u0026#39;, \u0026#39;传\u0026#39;, \u0026#39;动\u0026#39;; N=2 : \u0026#39;齿轮\u0026#39;, \u0026#39;轮传\u0026#39;, \u0026#39;传动\u0026#39;; N=3 : \u0026#39;齿轮传\u0026#39;, \u0026#39;轮传动\u0026#39;; N=4 : \u0026#39;齿轮传动\u0026#39;; 另外 mysql配置 1 show variables like \u0026#39;%token%\u0026#39; nnodb_ft_min_token_size 默认3，表示最小3个字符作为一个关键词，增大该值可减少全文索引的大小 innodb_ft_max_token_size 默认84，表示最大84个字符作为一个关键词，限制该值可减少全文索引的大小 ngram_token_size 默认2，表示2个字符作为内置分词解析器的一个关键词,合法取值范围是1-10，如对“abcd”建立全文索引，关键词为’ab’，‘bc’，‘cd’ 当使用ngram分词解析器时，innodb_ft_min_token_size和innodb_ft_max_token_size 无效\n在my.cnf中修改/添加参数 1 2 [mysqld] ngram_token_size = 1 修改启动参数 1 mysqld --ngram_token_size=1 参数均不可动态修改，修改后需重启MySQL服务，并重新建立全文索引\n语法 自然语言模式(NATURAL LANGUAGE MODE)\n自然语言模式是MySQL 默认的全文检索模式，也就是我们上方第三步搜索时，并没有指定使用哪种模式，默认就是自然语言模式，自然语言模式不能使用操作符，不能指定关键词必须出现或者必须不能出现等复杂查询，类似like。\nBOOLEAN模式(BOOLEAN MODE)\nBOOLEAN模式可以使用操作符，可以支持指定关键词必须出现或者必须不能出现或者关键词的权重高还是低等复杂查询。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026#39;apple banana\u0026#39; 无操作符，表示或，要么包含apple，要么包含banana \u0026#39;+apple +juice\u0026#39; 必须同时包含两个词 \u0026#39;+apple macintosh\u0026#39; 必须包含apple，但是如果也包含macintosh的话，相关性会更高。 \u0026#39;+apple -macintosh\u0026#39; 必须包含apple，同时不能包含macintosh。 \u0026#39;+apple ~macintosh\u0026#39; 必须包含apple，但是如果也包含macintosh的话，相关性要比不包含macintosh的记录低。 \u0026#39;+apple +(\u0026gt;juice \u0026lt;pie)\u0026#39; 查询必须包含apple和juice或者apple和pie的记录，但是apple juice的相关性要比apple pie高。 \u0026#39;apple*\u0026#39; 查询包含以apple开头的单词的记录，如apple、apples、applet。 \u0026#39;\u0026#34;some words\u0026#34;\u0026#39; 使用双引号把要搜素的词括起来，效果类似于like \u0026#39;%some words%\u0026#39;， 例如“some words of wisdom”会被匹配到，而“some noise words”就不会被匹配。 ","permalink":"https://habyss.github.io/posts/tech/mysql_like_fulltext/","summary":"需求 需要模糊查询文章的标题 探索 like 先测试一下300w数据量的耗时 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; select count(1) from t_banner 1 row retrieved starting from 1 in 160 ms (execution: 136 ms, fetching: 24 ms) 一共311402","title":"Mysql like模糊查询 fullText全文索引使用场景"},{"content":"标准写法 1 2 3 4 5 6 7 8 9 10 11 12 13 // 单例模式双重检查 private volatile static Singleton client; public static Singleton getSingleton() { if (client == null) { synchronized (Singleton.class) { if (client == null) { client = new Singleton(); } } } return client; } 线程并发涉及三个概念: 原子性 可见性 有序性\nvolatile的意义 1. 无volatile时 1 2 3 4 5 6 7 8 9 10 11 12 public static Singleton instance; public static Singleton getInstance() { if (instance == null) //1 { //2 synchronized(Singleton.class) { //3 if (instance == null) //4 instance = new Singleton(); //5 } } return instance; } ❓ 这种方式存在什么问题呢？\n也许有人说存在可见性问题：线程1执行完第5步，释放锁。线程2获得锁后执行到第4步，由于可见性的原因，发现instance还是null，从而初始化了两次。\n但是不会存在这种情况，因为synchronized能保证线程1在释放锁之前会讲对变量的修改刷新到主存当中，线程2拿到的值是最新的。\n实际存在的问题是无序性。\n第5步这个new操作是无序的，它可能会被编译成：\na. 先分配内存，让instance指向这块内存 b. 在内存中创建对象 然而我们需要意识到这么一个问题，synchronized虽然是互斥的，但不代表一次就把整个过程执行完，它在中间是可能释放时间片的，时间片不是锁。也就是说可能在a执行完后，时间片被释放，线程2执行到1，这时他读到的instance是不是null呢？（标记1）\n基于可见性，可能是null，也可能不是null。\n非常奇葩的是，在这个例子中，如果读到的是null，反而没问题了，接下来会等待锁，然后再次判断时不为null，最后返回单例。\n如果读到的不是null，那么坏了，按逻辑它就直接return instance了，这个instance还没执行构造参数，去做事情的话，很可能就崩溃了。\n2. 有volatitle时 1 2 3 4 5 6 7 8 9 10 11 12 public volatile static Singleton instance; public static Singleton getInstance() { if (instance == null) //1 { //2 synchronized(Singleton.class) { //3 if (instance == null) //4 instance = new Singleton(); //5 } } return instance; } 唯一的区别是加了volatile关键字，那么会有什么现象？\n这时要区分jdk版本了，在jdk1.4及之前，volatile并不能保证new操作的有序性，但是它能保证可见性，因此标记1处，读到的不是null，导致了问题。\n从1.5开始，加了volatile关键字的引用，它的初始化就不能是：\na. 先分配内存，让instance指向这块内存 b. 在内存中创建对象 而应该是：\na.在内存中创建对象 b.让instance指向这个对象. 这种形式，也就避免了无序性问题。\n","permalink":"https://habyss.github.io/posts/tech/single_double/","summary":"标准写法 1 2 3 4 5 6 7 8 9 10 11 12 13 // 单例模式双重检查 private volatile static Singleton client; public static Singleton getSingleton() { if (client == null) { synchronized (Singleton.class) { if (client == null) { client = new Singleton(); } } } return client; } 线程并发涉及三个概念:","title":"单例模式双重检查"},{"content":"1. 阿里云文件上传 前提设置好bucket和相应的url\ncontroller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Value(\u0026#34;${oss.bucket}\u0026#34;) private String bucketName; @Value(\u0026#34;${oss.fileURL}\u0026#34;) private String OSS_URL; @PostMapping(\u0026#34;singleUpload\u0026#34;) @ApiOperation(\u0026#34;单文件上传\u0026#34;) public ResponseResult\u0026lt;String\u0026gt; singleUpload( @ApiParam(\u0026#34;uni-app上传时 name属性\u0026#34;) @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file, @RequestParam(value = \u0026#34;folderType\u0026#34;, defaultValue = \u0026#34;6\u0026#34;) Integer folderType) { String originalFilename = file.getOriginalFilename(); String pathFileName = OSSFolderEnum.valueOfCode(folderType).getFolder() + LocalDateTime.now().format(DateTimePatterns.F_YYYY_MM_DD_HH_MM_SS_SSS) + Objects.requireNonNull(originalFilename).substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); OSSUtil.uploadFile(bucketName, pathFileName, file); String fileUrl = OSS_URL + pathFileName; return ResponseResult.createBySuccess(fileUrl); } utils, 单例模式双重检查获取client, 避免重复获取和释放\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 阿里云oss */ public class OSSUtil { public final static String endpoint = \u0026#34;\u0026#34;; public final static String accessKeyId = \u0026#34;\u0026#34;; public final static String accessKeySecret = \u0026#34;\u0026#34;; // 单例模式双重检查 private volatile static OSS client; public static OSS getOSSClient() { if (client == null) { synchronized (OSSUtil.class) { if (client == null) { client = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); } } } return client; } public static void uploadFile(String bucketName, String ObjectName, MultipartFile file) { OSS ossClient = getOSSClient(); try (InputStream ins = file.getInputStream()) { ossClient.putObject(bucketName, ObjectName, ins); } catch (Exception e) { throw new ServiceException(\u0026#34;文件上传异常, 请稍后再试\u0026#34;); } } public static void deleteFile(String bucketName, String urlPath) { OSS ossClient = getOSSClient(); ossClient.deleteObject(bucketName, urlPath); } } OSSFolderEnum, 不同分类的文件存放的路径\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Getter @AllArgsConstructor public enum OSSFolderEnum { USER_AVATAR(1, \u0026#34;web/avatar/\u0026#34;, \u0026#34;用户头像\u0026#34;), CONSULTATION_IMG(2, \u0026#34;web/xxxx/\u0026#34;, \u0026#34;xxx2\u0026#34;), HOSPITALIZATION(3, \u0026#34;web/xxx/\u0026#34;, \u0026#34;xxx3\u0026#34;), ARTICLE_IMG(4, \u0026#34;web/xxxxxx/\u0026#34;, \u0026#34;xxx4\u0026#34;), NOTICE_IMG(5, \u0026#34;web/notice/\u0026#34;, \u0026#34;xx5\u0026#34;), DEFAULT_IMG(6, \u0026#34;web/default/\u0026#34;, \u0026#34;DEFAULT\u0026#34;), ; private final int code; private final String folder; private final String desc; public static OSSFolderEnum valueOfCode(int code) { return Arrays.stream(OSSFolderEnum.values()) .filter(e -\u0026gt; e.getCode() == code) .findFirst() .orElse(DEFAULT_IMG); } } 2. 天翼云上传 controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Value(\u0026#34;${oos.bucket}\u0026#34;) private String bucketName; @Value(\u0026#34;${oos.fileURL}\u0026#34;) private String OOS_URL; @PostMapping(\u0026#34;singleUpload\u0026#34;) @ApiOperation(\u0026#34;单文件上传\u0026#34;) public ResponseResult\u0026lt;Object\u0026gt; singleUpload( @NotNull(message = \u0026#34;请选择照片上传\u0026#34;) @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file, @RequestParam(value = \u0026#34;folderType\u0026#34;, defaultValue = \u0026#34;6\u0026#34;) Integer folderType) { String originalFilename = file.getOriginalFilename(); String pathFileName = OSSFolderEnum.valueOfCode(folderType).getFolder() + LocalDateTime.now().format(DateTimePatterns.F_YYYY_MM_DD_HH_MM_SS_SSS) + Objects.requireNonNull(originalFilename).substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); OosUtil.uploadFile(bucketName, pathFileName, file); String fileUrl = OOS_URL + pathFileName; return ResponseResult.createBySuccess(fileUrl); } utils, 单例模式双重检查获取client, 避免重复获取和释放\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 public class OosUtil { private static final String accessKey = \u0026#34;\u0026#34;; private static final String secretKey = \u0026#34;\u0026#34;; private static final String endpoint = \u0026#34;\u0026#34;; // 单例模式双重检查 private volatile static AmazonS3 client; public static AmazonS3 getOOSClient() { if (client == null) { synchronized (OSSUtil.class) { if (client == null) { ClientConfiguration clientConfig = new ClientConfiguration(); // 设置连接的超时时间，单位毫秒 clientConfig.setConnectionTimeout(30 * 1000); // 设置 socket 超时时间，单位毫秒 clientConfig.setSocketTimeout(30 * 1000); clientConfig.setProtocol(Protocol.HTTP); //设置 http // 设置 V4 签名算法中负载是否参与签名 S3ClientOptions options = new S3ClientOptions(); options.setPayloadSigningEnabled(true); // 创建 client client = new AmazonS3Client( new PropertiesCredentials(accessKey, secretKey)); // 设置 endpoint client.setEndpoint(endpoint); //设置选项 client.setS3ClientOptions(options); } } } return client; } public static void uploadFile(String bucket, String fileName, MultipartFile file) { AmazonS3 oosClient = getOOSClient(); try (InputStream inputStream = file.getInputStream()) { oosClient.putObject(bucket, fileName, inputStream, null); } catch (Exception e) { throw new ServiceException(\u0026#34;上传文件失败, 请稍后再试\u0026#34;); } } public static void deleteFile(String bucketName, String urlPath) { getOOSClient().deleteObject(bucketName, urlPath); } } ","permalink":"https://habyss.github.io/posts/tech/oss_file_upload/","summary":"1. 阿里云文件上传 前提设置好bucket和相应的url controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Value(\u0026#34;${oss.bucket}\u0026#34;) private String bucketName; @Value(\u0026#34;${oss.fileURL}\u0026#34;) private String OSS_URL; @PostMapping(\u0026#34;singleUpload\u0026#34;) @ApiOperation(\u0026#","title":"阿里云/天翼云文件上传 单例优化"},{"content":"问题 使用mybatisPlus自带的saveBatch() 和 updateBatchById() 方法进行批量插入/更新时, 仅仅30条数据耗时3~5s.. 这很不正常\n原因 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public static \u0026lt;E\u0026gt; boolean executeBatch(Class\u0026lt;?\u0026gt; entityClass, Log log, Collection\u0026lt;E\u0026gt; list, int batchSize, BiConsumer\u0026lt;SqlSession, E\u0026gt; consumer) { Assert.isFalse(batchSize \u0026lt; 1, \u0026#34;batchSize must not be less than one\u0026#34;); return !CollectionUtils.isEmpty(list) \u0026amp;\u0026amp; executeBatch(entityClass, log, sqlSession -\u0026gt; { int size = list.size(); int idxLimit = Math.min(batchSize, size); int i = 1; for (E element : list) { consumer.accept(sqlSession, element); if (i == idxLimit) { sqlSession.flushStatements(); idxLimit = Math.min(idxLimit + batchSize, size); } i++; } }); } 日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ==\u0026gt; Preparing: INSERT INTO h_sort_table ( sort, update_time, create_time ) VALUES ( ?, ?, ? ) ==\u0026gt; Parameters: 1024(Long), 2022-12-05T14:41:28.705730(LocalDateTime), 2022-12-05T14:41:28.705730(LocalDateTime) ==\u0026gt; Parameters: 2048(Long), 2022-12-05T14:41:28.707724500(LocalDateTime), 2022-12-05T14:41:28.707724500(LocalDateTime) ==\u0026gt; Parameters: 3072(Long), 2022-12-05T14:41:28.708721100(LocalDateTime), 2022-12-05T14:41:28.708721100(LocalDateTime) ==\u0026gt; Parameters: 4096(Long), 2022-12-05T14:41:28.708721100(LocalDateTime), 2022-12-05T14:41:28.708721100(LocalDateTime) ==\u0026gt; Parameters: 5120(Long), 2022-12-05T14:41:28.709718200(LocalDateTime), 2022-12-05T14:41:28.709718200(LocalDateTime) ==\u0026gt; Parameters: 6144(Long), 2022-12-05T14:41:28.709718200(LocalDateTime), 2022-12-05T14:41:28.709718200(LocalDateTime) ==\u0026gt; Parameters: 7168(Long), 2022-12-05T14:41:28.709718200(LocalDateTime), 2022-12-05T14:41:28.709718200(LocalDateTime) ==\u0026gt; Parameters: 8192(Long), 2022-12-05T14:41:28.710715500(LocalDateTime), 2022-12-05T14:41:28.710715500(LocalDateTime) ==\u0026gt; Parameters: 9216(Long), 2022-12-05T14:41:28.711218100(LocalDateTime), 2022-12-05T14:41:28.711218100(LocalDateTime) ==\u0026gt; Parameters: 10240(Long), 2022-12-05T14:41:28.711218100(LocalDateTime), 2022-12-05T14:41:28.711218100(LocalDateTime) ==\u0026gt; Parameters: 11264(Long), 2022-12-05T14:41:28.711218100(LocalDateTime), 2022-12-05T14:41:28.711218100(LocalDateTime) ==\u0026gt; Parameters: 12288(Long), 2022-12-05T14:41:28.712222200(LocalDateTime), 2022-12-05T14:41:28.712222200(LocalDateTime) ==\u0026gt; Parameters: 13312(Long), 2022-12-05T14:41:28.713214500(LocalDateTime), 2022-12-05T14:41:28.713214500(LocalDateTime) ==\u0026gt; Parameters: 14336(Long), 2022-12-05T14:41:28.714212300(LocalDateTime), 2022-12-05T14:41:28.714212300(LocalDateTime) ==\u0026gt; Parameters: 15360(Long), 2022-12-05T14:41:28.715356500(LocalDateTime), 2022-12-05T14:41:28.715356500(LocalDateTime) ==\u0026gt; Parameters: 16384(Long), 2022-12-05T14:41:28.715356500(LocalDateTime), 2022-12-05T14:41:28.715356500(LocalDateTime) ==\u0026gt; Parameters: 17408(Long), 2022-12-05T14:41:28.716356500(LocalDateTime), 2022-12-05T14:41:28.716356500(LocalDateTime) ==\u0026gt; Parameters: 18432(Long), 2022-12-05T14:41:28.716356500(LocalDateTime), 2022-12-05T14:41:28.716356500(LocalDateTime) ==\u0026gt; Parameters: 19456(Long), 2022-12-05T14:41:28.717356(LocalDateTime), 2022-12-05T14:41:28.717356(LocalDateTime) ==\u0026gt; Parameters: 20480(Long), 2022-12-05T14:41:28.718350200(LocalDateTime), 2022-12-05T14:41:28.718350200(LocalDateTime) ==\u0026gt; Parameters: 21504(Long), 2022-12-05T14:41:28.718350200(LocalDateTime), 2022-12-05T14:41:28.718350200(LocalDateTime) ==\u0026gt; Parameters: 22528(Long), 2022-12-05T14:41:28.719348400(LocalDateTime), 2022-12-05T14:41:28.719348400(LocalDateTime) ==\u0026gt; Parameters: 23552(Long), 2022-12-05T14:41:28.719348400(LocalDateTime), 2022-12-05T14:41:28.719348400(LocalDateTime) ==\u0026gt; Parameters: 24576(Long), 2022-12-05T14:41:28.719348400(LocalDateTime), 2022-12-05T14:41:28.719348400(LocalDateTime) ==\u0026gt; Parameters: 25600(Long), 2022-12-05T14:41:28.720345700(LocalDateTime), 2022-12-05T14:41:28.720345700(LocalDateTime) ==\u0026gt; Parameters: 26624(Long), 2022-12-05T14:41:28.720345700(LocalDateTime), 2022-12-05T14:41:28.720345700(LocalDateTime) ==\u0026gt; Parameters: 27648(Long), 2022-12-05T14:41:28.721342300(LocalDateTime), 2022-12-05T14:41:28.721342300(LocalDateTime) ==\u0026gt; Parameters: 28672(Long), 2022-12-05T14:41:28.721342300(LocalDateTime), 2022-12-05T14:41:28.721342300(LocalDateTime) ==\u0026gt; Parameters: 29696(Long), 2022-12-05T14:41:28.722339400(LocalDateTime), 2022-12-05T14:41:28.722339400(LocalDateTime) ==\u0026gt; Parameters: 30720(Long), 2022-12-05T14:41:28.723336700(LocalDateTime), 2022-12-05T14:41:28.723336700(LocalDateTime) 请求耗时 : 4054ms 查看源码和日志可以看出, mybatisPlus是使用的循环单条数据插入, 这明显不符合我们高效的需求\n优化 方式一, xml中拼接 SQL语句是有长度限制，在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packet配置可以修改，默认是1M，测试时修改为8M。\n可以使用idea插件来代替我们手写xml, 比如MyBatisCodeHelper\ninsert:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;insert id=\u0026#34;insertList\u0026#34;\u0026gt; INSERT INTO h_sort_table( sort, id, update_time, create_time )VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;element\u0026#34; index=\u0026#34;index\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; ( #{element.sort}, #{element.id}, #{element.updateTime}, #{element.createTime} ) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; update:\n需要开启mysql的批量操作 \u0026amp;allowMultiQueries=true\nupdate的xml有多种写法, 这种是嘴贱大方便的\n其他的还有case when 以及 INSERT INTO … ON DUPLICATE KEY UPDATE\nsql语句for循环效率其实相当高的，因为它仅仅有一个循环体，只不过最后update语句比较多，量大了就有可能造成****sql阻塞****。\ncase when虽然最后只会有一条更新语句，但是xml中的循环体有点多，每一个case when 都要循环一遍list集合，所以****大批量拼sql的时候会比较慢****，所以效率问题严重。使用的时候建议分批插入。\nduplicate key update可以看出来是最快的，但是一般大公司都禁用，***公司一般都禁止使用replace into和INSERT INTO … ON DUPLICATE KEY UPDATE，这种sql有可能会造成数据丢失和主从上表的自增id值不一致*。**而且用这个更新时，记得一定要加上id，而且values（）括号里面放的是数据库字段，不是java对象的属性字段。\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;update id=\u0026#34;updateBatch\u0026#34; parameterType=\u0026#34;java.util.List\u0026#34; \u0026gt; \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34; open=\u0026#34;\u0026#34; close=\u0026#34;\u0026#34; separator=\u0026#34;;\u0026#34;\u0026gt; update h_sort_table \u0026lt;set \u0026gt; \u0026lt;if test=\u0026#34;item.sort != null\u0026#34; \u0026gt; sort = #{item.sort}, \u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{item.id,jdbcType=BIGINT} \u0026lt;/foreach\u0026gt; \u0026lt;/update\u0026gt; 方式二, 扩展mybatisPlus 添加 InsertBatchMethod 和 UpdateBatchMethod 类： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @Slf4j public class InsertBatchMethod extends AbstractMethod { @Override public MappedStatement injectMappedStatement(Class\u0026lt;?\u0026gt; mapperClass, Class\u0026lt;?\u0026gt; modelClass, TableInfo tableInfo) { final String sql = \u0026#34;\u0026lt;script\u0026gt;insert into %s %s values %s\u0026lt;/script\u0026gt;\u0026#34;; final String fieldSql = prepareFieldSql(tableInfo); final String valueSql = prepareValuesSql(tableInfo); final String sqlResult = String.format(sql, tableInfo.getTableName(), fieldSql, valueSql); // log.debug(\u0026#34;sqlResult-----\u0026gt;{}\u0026#34;, sqlResult); SqlSource sqlSource = languageDriver.createSqlSource(configuration, sqlResult, modelClass); return this.addInsertMappedStatement(mapperClass, modelClass, \u0026#34;insertBatch\u0026#34;, sqlSource, new NoKeyGenerator(), null, null); } private String prepareFieldSql(TableInfo tableInfo) { StringBuilder fieldSql = new StringBuilder(); fieldSql.append(tableInfo.getKeyColumn()).append(\u0026#34;,\u0026#34;); tableInfo.getFieldList().forEach(x -\u0026gt; fieldSql.append(x.getColumn()).append(\u0026#34;,\u0026#34;)); fieldSql.delete(fieldSql.length() - 1, fieldSql.length()); fieldSql.insert(0, \u0026#34;(\u0026#34;); fieldSql.append(\u0026#34;)\u0026#34;); return fieldSql.toString(); } private String prepareValuesSql(TableInfo tableInfo) { final StringBuilder valueSql = new StringBuilder(); valueSql.append(\u0026#34;\u0026lt;foreach collection=\\\u0026#34;list\\\u0026#34; item=\\\u0026#34;item\\\u0026#34; index=\\\u0026#34;index\\\u0026#34; open=\\\u0026#34;(\\\u0026#34; separator=\\\u0026#34;),(\\\u0026#34; close=\\\u0026#34;)\\\u0026#34;\u0026gt;\u0026#34;); valueSql.append(\u0026#34;#{item.\u0026#34;).append(tableInfo.getKeyProperty()).append(\u0026#34;},\u0026#34;); tableInfo.getFieldList().forEach(x -\u0026gt; valueSql.append(\u0026#34;#{item.\u0026#34;).append(x.getProperty()).append(\u0026#34;},\u0026#34;)); valueSql.delete(valueSql.length() - 1, valueSql.length()); valueSql.append(\u0026#34;\u0026lt;/foreach\u0026gt;\u0026#34;); return valueSql.toString(); } } @Slf4j public class UpdateBatchMethod extends AbstractMethod { @Override public MappedStatement injectMappedStatement(Class\u0026lt;?\u0026gt; mapperClass, Class\u0026lt;?\u0026gt; modelClass, TableInfo tableInfo) { String sql = \u0026#34;\u0026lt;script\u0026gt;\\n\u0026lt;foreach collection=\\\u0026#34;list\\\u0026#34; item=\\\u0026#34;item\\\u0026#34; separator=\\\u0026#34;;\\\u0026#34;\u0026gt;\\nupdate %s %s where %s=#{%s} %s\\n\u0026lt;/foreach\u0026gt;\\n\u0026lt;/script\u0026gt;\u0026#34;; String additional = tableInfo.isWithVersion() ? tableInfo.getVersionFieldInfo().getVersionOli(\u0026#34;item\u0026#34;, \u0026#34;item.\u0026#34;) : \u0026#34;\u0026#34; + tableInfo.getLogicDeleteSql(true, true); String setSql = sqlSet(tableInfo.isLogicDelete(), false, tableInfo, false, \u0026#34;item\u0026#34;, \u0026#34;item.\u0026#34;); String sqlResult = String.format(sql, tableInfo.getTableName(), setSql, tableInfo.getKeyColumn(), \u0026#34;item.\u0026#34; + tableInfo.getKeyProperty(), additional); // log.debug(\u0026#34;sqlResult-----\u0026gt;{}\u0026#34;, sqlResult); SqlSource sqlSource = languageDriver.createSqlSource(configuration, sqlResult, modelClass); return this.addUpdateMappedStatement(mapperClass, modelClass, \u0026#34;updateBatch\u0026#34;, sqlSource); } } 添加自定义方法SQL注入器 CustomizedSqlInjector： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class CustomizedSqlInjector extends DefaultSqlInjector { /** * 如果只需增加方法，保留mybatis plus自带方法， * 可以先获取super.getMethodList()，再添加add */ @Override public List\u0026lt;AbstractMethod\u0026gt; getMethodList(Class\u0026lt;?\u0026gt; mapperClass) { List\u0026lt;AbstractMethod\u0026gt; methodList = super.getMethodList(mapperClass); methodList.add(new InsertBatchMethod()); methodList.add(new UpdateBatchMethod()); return methodList; } } @Configuration @EnableTransactionManagement @MapperScan(\u0026#34;com.xxx.xxx.mapper\u0026#34;) public class MybatisPlusConfig { @Bean public CustomizedSqlInjector customizedSqlInjector() { return new CustomizedSqlInjector(); } } 添加通用 mapper 和 service： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public interface BasicMapper\u0026lt;T\u0026gt; extends BaseMapper\u0026lt;T\u0026gt; { /** * 自定义批量插入 */ int insertBatch(@Param(\u0026#34;list\u0026#34;) List\u0026lt;T\u0026gt; list); /** * 自定义批量更新，条件为主键 */ int updateBatch(@Param(\u0026#34;list\u0026#34;) List\u0026lt;T\u0026gt; list); } public interface BasicService\u0026lt;T\u0026gt; extends IService\u0026lt;T\u0026gt; { int insertBatch(List\u0026lt;T\u0026gt; list); int updateBatch(List\u0026lt;T\u0026gt; list); } public class BasicServiceImpl\u0026lt;M extends BasicMapper\u0026lt;T\u0026gt;, T\u0026gt; extends ServiceImpl\u0026lt;M, T\u0026gt; implements BasicService\u0026lt;T\u0026gt; { @Override public int insertBatch(List\u0026lt;T\u0026gt; list) { return baseMapper.insertBatch(list); } @Override public int updateBatch(List\u0026lt;T\u0026gt; list) { return baseMapper.updateBatch(list); } } 总结 项目中使用批量插入和批量更新的地方一般并不多, 推荐xml方式.\n当然如果项目中处理数据这种批量的业务比较多, 推荐扩展的方式, 后续只需要实现BasicService就ok了.\n","permalink":"https://habyss.github.io/posts/tech/mybatis_plus_batch/","summary":"问题 使用mybatisPlus自带的saveBatch() 和 updateBatchById() 方法进行批量插入/更新时, 仅仅30条数据耗时3~5s.. 这很不正常 原因 源码 1 2","title":"mybatisPlus下的批量插入修改 探索"},{"content":"简单demo实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 /** * 短链重定向 * * @param shortLink 短链接 * @param response 响应 * @throws IOException ioexception */ @GetMapping(\u0026#34;/s/{shortLink}\u0026#34;) public void shortLink(@PathVariable(\u0026#34;shortLink\u0026#34;) String shortLink, HttpServletResponse response) throws IOException { // 从数据库或者缓存中获取对应链接 String link = \u0026#34;https://www.baidu.com\u0026#34;; response.sendRedirect(StringUtils.hasText(link) ? link : \u0026#34;default\u0026#34;); } /** * 获取短链 * * @param link 链接 * @return {@link String} */ @PostMapping(\u0026#34;shortLink\u0026#34;) public String getLink(String link) { // 生成短链code, 并存储数据库 return shortUrl(link).stream() .dropWhile(this::notExistInDb) .findAny() .orElseThrow(() -\u0026gt; new RuntimeException(\u0026#34;链接生成错误, 稍后重试\u0026#34;)); } /** * 数据库是否存在对应短链 * * @param shortCode 短网址 * @return boolean */ private boolean notExistInDb(String shortCode) { // 去数据库查询 sql可优化为 limit 1; return Instant.now().toEpochMilli() % 2 == 0; } /** * 4组6位短链接字符串 * * @param url url * @return {@link List}\u0026lt;{@link String}\u0026gt; */ public static List\u0026lt;String\u0026gt; shortUrl(String url) { // 可以自定义生成 MD5 加密字符传前的混合 KEY String key = Instant.now().toString(); // 要使用生成 URL 的字符 String[] chars = new String[]{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34;, \u0026#34;g\u0026#34;, \u0026#34;h\u0026#34;, \u0026#34;i\u0026#34;, \u0026#34;j\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;n\u0026#34;, \u0026#34;o\u0026#34;, \u0026#34;p\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;r\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;t\u0026#34;, \u0026#34;u\u0026#34;, \u0026#34;v\u0026#34;, \u0026#34;w\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;5\u0026#34;, \u0026#34;6\u0026#34;, \u0026#34;7\u0026#34;, \u0026#34;8\u0026#34;, \u0026#34;9\u0026#34;, \u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;, \u0026#34;F\u0026#34;, \u0026#34;G\u0026#34;, \u0026#34;H\u0026#34;, \u0026#34;I\u0026#34;, \u0026#34;J\u0026#34;, \u0026#34;K\u0026#34;, \u0026#34;L\u0026#34;, \u0026#34;M\u0026#34;, \u0026#34;N\u0026#34;, \u0026#34;O\u0026#34;, \u0026#34;P\u0026#34;, \u0026#34;Q\u0026#34;, \u0026#34;R\u0026#34;, \u0026#34;S\u0026#34;, \u0026#34;T\u0026#34;, \u0026#34;U\u0026#34;, \u0026#34;V\u0026#34;, \u0026#34;W\u0026#34;, \u0026#34;X\u0026#34;, \u0026#34;Y\u0026#34;, \u0026#34;Z\u0026#34; }; // 对传入网址进行 MD5 加密 String sMD5EncryptResult = DigestUtils.md5DigestAsHex((key + url).getBytes()).toUpperCase(); ArrayList\u0026lt;String\u0026gt; results = new ArrayList\u0026lt;\u0026gt;(); //得到 4组短链接字符串 for (int i = 0; i \u0026lt; 4; i++) { // 把加密字符按照 8 位一组 16 进制与 0x3FFFFFFF 进行位与运算 String sTempSubString = sMD5EncryptResult.substring(i * 8, i * 8 + 8); // 这里需要使用 long 型来转换，因为 Inteper .parseInt() 只能处理 31 位 , 首位为符号位 , 如果不用 long ，则会越界 long lHexLong = 0x3FFFFFFF \u0026amp; Long.parseLong(sTempSubString, 16); StringBuilder outChars = new StringBuilder(); //循环获得每组6位的字符串 for (int j = 0; j \u0026lt; 6; j++) { // 把得到的值与 0x0000003D 进行位与运算，取得字符数组 chars 索引(具体需要看chars数组的长度 以防下标溢出，注意起点为0) long index = 0x0000003D \u0026amp; lHexLong; // 把取得的字符相加 outChars.append(chars[(int) index]); // 每次循环按位右移 5 位 lHexLong = lHexLong \u0026gt;\u0026gt; 5; } // 把字符串存入对应索引的输出数组 results.add(outChars.toString()); } // 把字符串存入对应索引的输出数组 return results; } 业务需要分享页面, 在发送短信或者消息时带的原链接太长了, 需要使用短链接优化, 由于是自己业务使用, 不涉及用户自定义链接的部分, 所以就自己搭建了简单的短链服务.\n短链-摘要算法 将长网址md5生成32位签名串, 分为4段, 每段8个字节； 对这四段循环处理, 取8个字节, 将他看成16进制串与0x3fffffff(30位1)与操作, 即超过30位的忽略处理； 这30位分成6段, 每5位的数字作为字母表的索引取得特定字符, 依次进行获得6位字符串； 总的md5串可以获得4个6位串；取里面的任意一个就可作为这个长url的短url地址； 这种算法,虽然会生成4个,但是仍然存在重复几率。\n虽然几率很小，但是该方法依然存在碰撞的可能性, 所以使用了时间key混淆, 让用户稍后重试.\n存储/缓存 视情况而定, 比如失效时间, 域名单独保存, 将最近的热点数据缓存 等等\n","permalink":"https://habyss.github.io/posts/tech/shorturl/","summary":"简单demo代码, 短链生成算法, 重定向方式, 存储方式和缓存根据业务情况实现","title":"短链服务实现"},{"content":"问题 在我们使用git的时候, 有时候可能某些功能代码不需要了, 或者版本, 或者误提交之类的, 需要将远程的代码回退到某个特定的版本\n因为涉及大量代码的修改, 导致一个个的文件改回再提交的话会非常麻烦\n这里记录了在Intellij Idea中回滚远程代码的操作\n回滚操作 1. 回滚本地代码 先复制要回滚的版本号\n然后选择菜单懒 Git-\u0026gt;Repository-\u0026gt;Reset HEAD\nReset Type 有三种：\nmixed 默认方式，只保留源码，回退 commit 和 index 信息 soft 回退到某个版本，只回退了 commit 的信息，不会恢复到 index file 一级。如果还要提交，直接 commit hard 彻底回退，本地源码也会变成上一个版本内容\n此时我们选择 Hard 彻底回退, 填入版本号, 点击 Reset 就能将本地代码版本回滚到指定版本。\n2. 回滚远程代码 第一种，直接强制提交，使用 git 命令提交 git push -f，但是这样会把回滚版本之后的提交记录全部删除，因此不建议这样做。\n第二种，用前面我们回滚本地的方式，再次回滚到最新版本。\n跟之前一样的操作, 不过是最新的版本号.\n再次 Git-\u0026gt;Repository-\u0026gt;Reset HEAD, Reset Type 采用 Mixed 方式将源码保留，然后点击 Reset。\n此时代码已经是旧版本的代码，并且版本还是最新版本，此时正常提交 push 后本地和远程代码的回滚就完成了。\n","permalink":"https://habyss.github.io/posts/tool/git_reset/","summary":"将远程的代码回滚到某个版本","title":"Git回滚方式 Idea"},{"content":"Java中的锁 1. 乐观锁 一种乐观思想, 读取数据的时候乐观的认为别的线程不会进行修改, 所以读取的时候不上锁. 当更新的时候上锁, 并判断当前值是否与期望的相同, 相同则更新.\njava中的本地方法cas, 数据库一般的version字段\n2. 悲观锁 一种悲观思想, 每次读数据的时候都悲观的认为别的线程会进行修改 , 所以读取的时候上锁. 只能有一个线程进行读写操作.\njava中的synchronized, ReentrantLock\n3. 自旋锁 为了避免线程切换的开销, 让一个线程执行循环操作, 而为了避免长时间占用处理器时间, 一战有默认的自旋次数, java默认10次, 之后会使用传统的方式挂起线程.\njava中cas比较失败后的自旋\n4. 可重入锁 可有效避免死锁, 任意一个线程在获取锁之后能再次获取锁, 但其他线程不可获取锁, 不会被锁阻塞. 内置计数器\njava中的ReentrantLock, synchronized修饰\n5. 读写锁 ReentrantReadWriteLock, 分为读锁和写锁, 多个读锁不互斥, 读锁和写锁互斥.\n读锁\u0026gt;允许多个线程获取读锁, 同时访问同一个资源\n写锁\u0026gt;只允许一个线程获取写锁, 不允许同时访问同一个资源\n6. 公平锁 按照申请所的顺序来获取锁, 在并发环境中, 每个线程会先查看此锁维护的等待队列, 如果为空, 则站有锁, 如果不为空, 则加入到队列的末尾, 按照先进先出的原则占有锁.\n7. 非公平锁 线程先尝试获取锁, 如果获取不到, 再采用公平锁的方式. 即如果当时锁的状态刚好是没有被占用的话, 直接占有锁, 不必等待和切换.\n性能会高于公平锁, 但是有可能造成线程饥饿(某个线程很长时间内获取不到锁)\nsynchronnized, ReentrantLock可指定, 但默认是非公平锁\n8. 共享锁 多个线程可以同时获取锁, 以共享的方式持有锁.\njava中的ReentrantReadWriteLock\n9. 独占锁 只能有一个线程获取锁\njava中的synchronnized, ReentrantLock\n10. ","permalink":"https://habyss.github.io/posts/tech/java%E4%B8%AD%E7%9A%84%E9%94%81/","summary":"Java中的锁 1. 乐观锁 一种乐观思想, 读取数据的时候乐观的认为别的线程不会进行修改, 所以读取的时候不上锁. 当更新的时候上锁, 并判断当前值是否与","title":"Java中的锁"},{"content":"策略模式 策略模式是一种行为模式，也是替代大量 if else 的利器。他能帮你解决的场景，一般是具有同类可替代的行为逻辑算法场景。\n比如：\n不同类型的交易方式（信用卡、支付宝、微信） 不同的登录方式（用户名密码、手机号、邮箱） 生成唯一的ID策略（UUID、自增、雪花算法、Leaf算法） 以上场景都可以使用策略模式包装，提供给外部使用。\n模板模式 模板模式的核心设计思路是通过在抽象类中定义抽象方法的执行顺序，并将抽象方法设定为只有子类实现，但不设计独立访问的方法。\n代码 定义枚举 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public enum SignInMode { /** * 验证码登录 */ SMS_CODE, /** * 微信登录 */ WEI_XIN, /** * 秒验 */ MIAO_YAN, /** * 密码 */ PASS_WORD; } 定义接口 1 2 3 4 5 6 public interface SignInHandler { boolean support(@NonNull SignInMode mode); String signIn(@NonNull AppSignInInput input); } 定义抽象实现类(模板) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Slf4j public abstract class AbstractSignInHandler implements SignInHandler { @Override public String signIn(AppSignInInput input) { // 不同的登陆方式获取手机号的方式不一致 // 处理后的额外参数attachments String phoneNo = getPhoneNo(input, attachments); Verify.verifyNotNull(phoneNo); // 手机号登录或注册 并获取用户信息 Pair\u0026lt;Integer, LocalDateTime\u0026gt; result = accountAuthService.signInOrSignUp(phoneNo); Integer accountId = result.getKey(); LocalDateTime signUpTime = result.getValue(); // 获取账号信息 AppAccountInfoRecord accountInfoRecord = getAccount(accountId); // 生成token返回 并在redis存储用户信息 ... return token; } /** * 获取校验过后的格式正确的手机号码 */ protected abstract String getPhoneNo(AppSignInInput input, Map\u0026lt;String, Object\u0026gt; attachments); 定义不同的策略 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component public class PassWordSignInHandler extends AbstractSignInHandler { @Override public boolean support(SignInMode mode) { return SignInMode.PASS_WORD == mode; } @Override protected String getPhoneNo(AppSignInInput input, Map\u0026lt;String, Object\u0026gt; attachments) { return \u0026#34;phoneNo\u0026#34;; } } 调用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Slf4j @Component public class SignInManager { @Resource private List\u0026lt;SignInHandler\u0026gt; handlers; public String signIn(@NonNull AppSignInInput input) { SignInMode signInMode = input.getSignInMode(); return handlers.stream() .filter(it -\u0026gt; it.support(signInMode)) .findFirst() .orElseThrow(() -\u0026gt; new RuntimeException(\u0026#34;不支持的的登录模式:\u0026#34; + signInMode)) .signIn(input); } } 总结 策略模式：\n在login方法中通过不同登录类型，交给指定的类执行登录逻辑。（也就是找模板） 各种模板注入到 List\u0026lt;SignInHandler\u0026gt; handlers 中 模板模式：\n首先定义了一个 SignInHandler 接口，其中定义了登录相关抽象方法 在抽象类 AbstractSignInHandler 中实现登录相关方法，供外部调用，这个类是模板模式的灵魂 💡 根据项目情况作出适当修改变动\n","permalink":"https://habyss.github.io/posts/tech/%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F-%E7%99%BB%E5%BD%95%E4%BC%98%E5%8C%96/","summary":"策略模式 策略模式是一种行为模式，也是替代大量 if else 的利器。他能帮你解决的场景，一般是具有同类可替代的行为逻辑算法场景。 比如： 不同类型的交易方式","title":"模板模式\u0026策略模式-登录优化"},{"content":"springboot启动时会显示自带的banner, 这个是可以自定义的, 记录一下.\n我们只需要在springboot项目的resources文件夹下创建一个banner.txt文件即可.\n定制banner的网站\nhttps://patorjk.com/software/taag\n","permalink":"https://habyss.github.io/posts/tool/springboot_banner/","summary":"springboot启动时会显示自带的banner, 这个是可以自定义的, 记录一下. 我们只需要在springboot项目的resources文","title":"SprintBoot下的banner.text"},{"content":"全局拦截, 在 MDC 中插入自定义 traceId 💡 MDC（Mapped Diagnostic Context）机制实现，支持主流的Log4j、Log4j2和Logback日志框架。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Order(Ordered.HIGHEST_PRECEDENCE) @Component @Slf4j public class TraceIdFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { // 服务间透传traceId String traceId = request.getHeader(TraceIdUtil.TRACE_ID); if (StringUtils.hasText(traceId)){ TraceIdUtil.resetTraceId(traceId); }else { TraceIdUtil.resetTraceId(); } log.info(\u0026#34;---请求地址: {} - {}\u0026#34;, request.getServletPath(), request.getQueryString()); chain.doFilter(request, response); } } 工具类 TraceIdUtils 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @UtilityClass public class TraceIdUtils { public final static String TRACE_ID = \u0026#34;traceId\u0026#34;; public final static String DELIMITER = \u0026#34;-\u0026#34;; public final static String EMPTY = \u0026#34;\u0026#34;; /** * 重置 traceId. * 为保证链路, 请求中有[异步/多线程]执行时, * 需先获取当前traceId{@link TraceIdUtils#getTraceId()}, 然后在新线程中设置traceId * * @param uuid the uuid */ public void resetTraceId(String uuid) { MDC.put(TRACE_ID, uuid); } /** * 重置/初始化 traceId. */ public void resetTraceId() { MDC.put(TRACE_ID, UUID.randomUUID().toString().replaceAll(DELIMITER, EMPTY)); } /** * 获取当前 traceId. * * @return the trace id */ public String getTraceId() { return MDC.get(TRACE_ID); } /** * 删除当前 traceId. */ public void remove() { MDC.remove(TRACE_ID); } } 日志输出配置文件 logback.xml 💡 在适当位置添加 %X{traceId} , 取出在 MDC 中设置的 traceId\n1 2 3 \u0026lt;pattern\u0026gt; %d{yyyy-MM-dd HH:mm:ss.SSS} %p %X{traceId} (%file:%line\\) - %m%n \u0026lt;/pattern\u0026gt; 微服务透传openFeign 在请求头中加入traceId, 并在TraceIdFilter中读取请求头\n1 2 3 4 5 6 7 8 9 @Component public class OpenFeignRequestInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate requestTemplate) { String traceId = TraceIdUtil.getTraceId(); requestTemplate.header(TraceIdUtil.TRACE_ID, traceId); } } ","permalink":"https://habyss.github.io/posts/tech/springboot_traceid/","summary":"全局拦截, 在 MDC 中插入自定义 traceId 💡 MDC（Mapped Diagnostic Context）机制实现，支持主流的Log4j、Log4j2和Logback日志框架。 1","title":"TraceId 日志跟踪"},{"content":"RabbitMq 生产者确认消息被消费 探索 消费者手动ack的一些状态, 生产者是不能准确得知的.\n例如:\n1 2 // 处理失败 重新进入队列 继续消费 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,true); 当消费者把消息重新放入队列, 生产者是不知道的\n….\n而 生产者的 convertSendAndReceive 虽然可以得知返回信息, 但是它是有次数限制的, 而次数是提前设定好的, 如果次数范围内没有处理成功, 则会接收到null.\n所以仍不能准确得知消费者的状态.\n生产者不能准确得知消费者是否成功消费了消息 配置文件 application.yml中增加配置\n1 2 3 4 spring: rabbitmq: publisher-confirms: true publisher-returns: true 生产者可以实现 RabbitTemplate.ReturnCallback, 来获取消息在发送到路由或者队列中的失败信息\n普通创建类方式\n定义ReturnCallBackService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Component public class ReturnCallBackService implements RabbitTemplate.ReturnCallback { /** * 发送到路由或者队列中的失败信息 * * @param message the returned message. * @param replyCode the reply code. * @param replyText the reply text. * @param exchange the exchange. * @param routingKey the routing key. */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) { System.out.println(\u0026#34;return--message:\u0026#34; + new String(message.getBody()) + \u0026#34;,replyCode:\u0026#34; + replyCode + \u0026#34;,replyText:\u0026#34; + replyText + \u0026#34;,exchange:\u0026#34; + exchange + \u0026#34;,routingKey:\u0026#34; + routingKey); } } 生产者发送消息之前设置\n1 rabbitTemplate.setReturnCallback(returnCallBackService); jdk8, 匿名函数\n发送消息之前设置\n1 2 3 4 rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -\u0026gt; { logger.info(\u0026#34;send message failed: \u0026#34; + replyCode + \u0026#34; \u0026#34; + replyText); rabbitTemplate.send(message); }); 生产者可以实现 RabbitTemplate.ConfirmCallback, 来确认消息是否发送到具体路由或者队列\n普通创建类方式\n定义ConfirmCallback\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component public class ConfirmCallbackService implements RabbitTemplate.ConfirmCallback { /** * 确认消息是否发送到具体路由或者队列 * * @param correlationData correlation data for the callback. * @param ack true for ack, false for nack * @param cause An optional cause, for nack, when available, otherwise null. */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { System.out.println(\u0026#34;correlationData.getId() = \u0026#34; + correlationData.getId()); System.out.println(\u0026#34;ack = \u0026#34; + ack); if (ack){ System.err.println(\u0026#34;===============消息发送成功============\u0026#34;); }else { //发送失败 System.err.println(\u0026#34;================失败==================\u0026#34;); } System.out.println(\u0026#34;cause = \u0026#34; + cause); } } 生产者发送消息之前设置\n1 rabbitTemplate.setConfirmCallback(confirmCallbackService); jdk8, 匿名函数\n发送消息之前设置\n1 2 3 4 5 6 7 8 9 rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -\u0026gt; { if (ack) { logger.info(\u0026#34;send message success: data [\u0026#34; + correlationData.getId() + \u0026#34;]\u0026#34;); // 清除重试机制缓存 // retryCache.del(Long.valueOf(correlationData.getId())); } else { logger.info(\u0026#34;send message failed: \u0026#34; + cause + correlationData.toString()); } }); 手动ack 消费者的 @RabbitListener 注解中有 containerFactory 字段, 可以指定一个自定义的 containerFactory .\n创建自定义可以手动ack的 containerFactory:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class ConsumeConfig { @Resource ConnectionFactory connectionFactory; @Bean(\u0026#34;rabbitListenerContainerFactoryAck\u0026#34;) public RabbitListenerContainerFactory\u0026lt;?\u0026gt; rabbitListenerContainerFactoryAck(){ SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); return factory; } } 在需要手动ack的方法上指定 bean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @RabbitListener(queues = \u0026#34;update.crm.staff\u0026#34;,containerFactory = \u0026#34;rabbitListenerContainerFactoryAck\u0026#34;) @RabbitHandler public void updateCrmStaff(Channel channel, Message msg){ System.err.println(\u0026#34;========================消费开始================\u0026#34;); try { byte[] body = msg.getBody(); String s = new String(body); JSONObject crmAgent = JSONObject.parseObject(s); // 处理失败 重新进入队列 继续消费 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,true); } catch (IOException e) { e.printStackTrace(); try { //处理失败,丢弃消息 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,false); } catch (IOException e1) { e1.printStackTrace(); } } // 手动确认消费 channel.basicAck(msg.getMessageProperties().getDeliveryTag(), false); System.err.println(\u0026#34;========================消费结束================\u0026#34;); } } ","permalink":"https://habyss.github.io/posts/tech/rabbitmq_ack/","summary":"RabbitMq 生产者确认消息被消费 探索 消费者手动ack的一些状态, 生产者是不能准确得知的. 例如: 1 2 // 处理失败 重新进入队列 继续消费 channel.basicNack(msg.getMessageProperties().getDeliveryTag(), false,true); 当消费者把消息重新","title":"rabbitmq ack 探索"},{"content":"高并发情况下 RabbitMQ 服务限流 spring下默认为250, 若默写服务需要限流或者需要强制顺序性执行, 则需要自定义qos\n1 2 3 4 5 @RabbitHandler @RabbitListener(queues = QueueConstant.RE_SMS_ORDER_NOT_PAID_QUEUE) public void process(Channel channel, Message message) throws IOException { channel.basicQos(12); } 多个消费者同时消费一个消息 使用广播模式, 监听时不指定队列, 则会产生随即队列\n为了防止系统迭代重启产生的大量随机队列, 需要断开时删除随机队列\n1 2 3 4 5 @RabbitListener(bindings = @QueueBinding( //注意这里不要定义队列名称,系统会随机产生 value = @Queue(exclusive = \u0026#34;true\u0026#34;),// exclusive = \u0026#34;true\u0026#34; 断开时删除随机队列 避免系统迭代重启产生的大量随机队列 exchange = @Exchange(value = \u0026#34;填写交换机名称\u0026#34;, type = ExchangeTypes.FANOUT) )) ","permalink":"https://habyss.github.io/posts/tech/rabbitmq_qos_random/","summary":"高并发情况下 RabbitMQ 服务限流 spring下默认为250, 若默写服务需要限流或者需要强制顺序性执行, 则需要自定义qos 1 2 3 4 5 @RabbitHandler @RabbitListener(queues = QueueConstant.RE_SMS_ORDER_NOT_PAID_QUEUE) public void process(Channel channel, Message message)","title":"rabbitmq限流Qos 多个消费者同时消费一个消息"},{"content":"方式一: 原生RabbitMq延时队列 💡缺点: 每个队列的消息是顺序的, 靠后的过期时间短的消息并不能先执行\n配置队列 机制\n“死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况：\n消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。 消息在队列的存活时间超过设置的TTL时间。 消息队列的消息数量已经超过最大队列长度。 思路:\n声明一个默认队列 或 交换机绑定的队列, 不设置消费者, 称为死信队列 死信队列设置转发交换机以及路由 生产者设置消息过期时间 或 死信队列统一设置过期时间 过期后转发至新的交换机/队列进行消费 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 @Component public class DelayRabbitSmsOrderConfig { /** * 重发 */ public static final String RE_SMS_ORSER_EXCHANGE = \u0026#34;re.sms.order\u0026#34;; public static final String RE_SMS_ORDER_NOT_PAID_K = \u0026#34;re.sms.order.not.k.paid\u0026#34;; public static final String RE_SMS_ORDER_NOT_PAID_QUEUE = \u0026#34;re.sms.order.not.q.paid\u0026#34;; /** * 死信 */ public static final String DL_SMS_ORSER_EXCHANGE = \u0026#34;dead.sms.order\u0026#34;; public static final String DL_SMS_ORDER_NOT_PAID_K = \u0026#34;dead.sms.order.not.k.paid\u0026#34;; public static final String DL_SMS_ORDER_NOT_PAID_QUEUE = \u0026#34;dead.sms.order.not.q.paid\u0026#34;; /** * 声明重发交换机 */ @Bean public Exchange reExchange() { return ExchangeBuilder .directExchange(RE_SMS_ORSER_EXCHANGE) .durable(true) .build(); } /** * 声明重发队列 */ @Bean public Queue reQueue() { return QueueBuilder .durable(RE_SMS_ORDER_NOT_PAID_QUEUE) .build(); } /** * 绑定重发交换机 重发路由 */ @Bean public Binding reExchangeBinding(Exchange reExchange, Queue reQueue) { return BindingBuilder .bind(reQueue) .to(reExchange) .with(RE_SMS_ORDER_NOT_PAID_K) .noargs(); } /** * 声明死信队列 */ @Bean public Queue dlQueue() { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(4); // 指定过期之后的交换机为重发交换机 args.put(\u0026#34;x-dead-letter-exchange\u0026#34;, RE_SMS_ORSER_EXCHANGE); // 指定过期之后的路由为重发路由 args.put(\u0026#34;x-dead-letter-routing-key\u0026#34;, RE_SMS_ORDER_NOT_PAID_K); // 统一的毫秒单位过期 如果过期时间是动态的,需要rabbitMq插件,并在每条消息上设置过期时间 args.put(\u0026#34;x-expires\u0026#34;, \u0026#34;600000\u0026#34;); return QueueBuilder .durable(DL_SMS_ORDER_NOT_PAID_QUEUE) .withArguments(args) .build(); } // 下面两个可不设置, 则消费者发消息的时候不设置交换机和路由(即使用默认的交换机) /** * 声明死信交换机 */ @Bean public Exchange dlExchange() { return ExchangeBuilder .directExchange(DL_SMS_ORSER_EXCHANGE) .durable(true) .build(); } /** * 绑定死信交换机 死信路由 */ @Bean public Binding dlExchangeBinding(Exchange dlExchange, Queue dlQueue) { return BindingBuilder .bind(dlQueue) .to(dlExchange) .with(DL_SMS_ORDER_NOT_PAID_K) .noargs(); } } 生产者 1 2 3 4 5 6 7 8 9 10 11 12 // 延时 创单10min未支付 Message msg = MessageBuilder.withBody(params.getBytes()) .setContentType(MessageProperties.CONTENT_TYPE_JSON) .setContentEncoding(\u0026#34;utf-8\u0026#34;) // 若上面配置设置了死信交换机/死信路由 则配置上 .setReceivedExchange(\u0026#34;\u0026#34;) .setReceivedRoutingKey(\u0026#34;\u0026#34;) .setMessageId(UUID.randomUUID() + \u0026#34;\u0026#34;) // 若上面配置设置了统一的毫秒单位过期, 则不用配置 .setExpiration(\u0026#34;600000\u0026#34;) .build(); amqpTemplate.convertAndSend(QueueConstant.DEAD_SMS_ORDER_QUEUE, msg); 消费者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Component public class SmsPushNotPaidReceiver { public static final Logger logger = LoggerFactory.getLogger(SmsPushNotPaidReceiver.class); @RabbitHandler // 监听重发队列 @RabbitListener(queues = QueueConstant.RE_SMS_ORDER_NOT_PAID_QUEUE) public void process(Message message) { logger.info(\u0026#34;----------- sms.notPayOrder start -----------\u0026#34;); String params = new String(message.getBody(), StandardCharsets.UTF_8); JSONObject param = JSONObject.parseObject(params); String code = param.getString(\u0026#34;code\u0026#34;); logger.info(\u0026#34;----------- sms.notPayOrder end -----------\u0026#34;); } } 方式二: 插件RabbitMq延时队列 💡 没有了原生的缺点..\n💡 需要在服务器上自己装延时队列的插件, 简单\n配置队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Bean CustomExchange delayExchange() { //创建一个自定义交换机，可以发送延迟消息 Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-delayed-type\u0026#34;, \u0026#34;direct\u0026#34;); return new CustomExchange(QueueEnum.QUEUE_CONSULTATION_END.getExchange(), \u0026#34;x-delayed-message\u0026#34;, true, false, args); } // 添加其他延时队列时, 重复下面两个 @Bean public Queue consultationEndDelayQueue() { return new Queue(QueueEnum.QUEUE_CONSULTATION_END.getQueueName(), true); } @Bean public Binding consultationEndDelayBinding(CustomExchange delayExchange, Queue consultationEndDelayQueue) { return BindingBuilder .bind(consultationEndDelayQueue) .to(delayExchange) .with(QueueEnum.QUEUE_CONSULTATION_END.getRoutingKey()) .noargs(); } 生产者 1 2 3 4 5 6 7 8 9 10 11 CommonEvent commonEvent = new CommonEvent().setId(id); long delayTime = timeoutConstant.getImageTextAutoEnd() * 60 * 60 * 1000L; rabbitTemplate.convertAndSend( QueueEnum.QUEUE_CONSULTATION_END.getExchange(), QueueEnum.QUEUE_CONSULTATION_END.getRoutingKey(), commonEvent, message -\u0026gt; { //给消息设置延迟毫秒值 message.getMessageProperties().setHeader(\u0026#34;x-delay\u0026#34;, delayTime); return message; }); 消费者 1 2 3 4 5 6 7 8 9 @Component @RabbitListener(queues = \u0026#34;consultation.end\u0026#34;) public class ConsultationCancelReceiver { @RabbitHandler public void handle(CommonEvent commonEvent) { } } ","permalink":"https://habyss.github.io/posts/tech/rabbitmq_delay/","summary":"方式一: 原生RabbitMq延时队列 💡缺点: 每个队列的消息是顺序的, 靠后的过期时间短的消息并不能先执行 配置队列 机制 “死信”是RabbitMQ","title":"rabbitmq实现延时队列"},{"content":"方式一: 基于表达式 例如简单日志打印: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Slf4j @Aspect @Component public class WebLogAspect { /** * xxx包及其子包下的以Controller结尾的类的任意方法 */ @Pointcut(\u0026#34;execution(public * com.xxx..*Controller.*(..))\u0026#34;) public void webLog(){} @Around(\u0026#34;webLog()\u0026#34;) public Object around(ProceedingJoinPoint jp) throws Throwable { StopWatch sw = new StopWatch(\u0026#34;请求耗时\u0026#34;); ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = Objects.requireNonNull(attributes).getRequest(); sw.start(); log.info(\u0026#34;---请求来源 : {}\u0026#34;, IpUtil.getIpAddress(request)); log.info(\u0026#34;---请求方法 : {}.{}\u0026#34;, jp.getSignature().getDeclaringTypeName(), jp.getSignature().getName()); log.info(\u0026#34;---请求参数 : {}\u0026#34;, Arrays.toString(jp.getArgs())); Object result = jp.proceed(); sw.stop(); log.info(\u0026#34;---请求耗时 : {}{}\u0026#34;, sw.getLastTaskTimeMillis(), \u0026#34;ms\u0026#34;); log.info(\u0026#34;---请求返回 : {}\u0026#34;, result); return result; } } 方式二: 基于注解 说明\n@Target({ElementType.TYPE, ElementType.METHOD}) ：允许使用的地方；如-ElementType.TYPE==》类；ElementType.METHOD==》方法\n@Retention(RetentionPolicy.RUNTIME)：注解保留在程序运行期间，此时可以通过反射获得定义在某个类上的所有注解\n@Inherited：当@Inherited修饰过的注解加在某个类A上时，假如类B继承了A，则B也会带上该注解。加在接口上无效\n例如基于注解的redis缓存实现: 定义注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Retention(RetentionPolicy.RUNTIME) // 一般是运行时 @Target(ElementType.METHOD) // 注解级别 此处为方法级 @Order(Ordered.HIGHEST_PRECEDENCE) // 优先级 public @interface RedisCache { /** * key * * @return {@link String} */ String key(); /** * 过期时间 * * @return int */ long expire() default 1; /** * 时间单位 * * @return {@link TimeUnit} */ TimeUnit timeUnit() default TimeUnit.DAYS; /** * 方法返回为list集合时 必传 否则出错 * * @return {@link Class} */ Class\u0026lt;?\u0026gt; listForClass() default RedisCache.class; } 为注解增加aop相关实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Aspect @Component @Slf4j public class RedisCacheContract { @Resource RedisUtil redisUtil; @Around(\u0026#34;@annotation(redisCache)\u0026#34;) public Object redisAround(final ProceedingJoinPoint joinPoint, RedisCache redisCache) throws Throwable { Object result; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); String key = redisCache.key() + \u0026#34;:\u0026#34; + Arrays.toString(joinPoint.getArgs()); if (redisUtil.hasKey(key)) { log.info(\u0026#34;hint redisCache {}\u0026#34;, key); // 默认注解 直接使用原方法的returnType来解析json if (redisCache.listForClass().isAssignableFrom(RedisCache.class)) { Class\u0026lt;?\u0026gt; returnType = signature.getReturnType(); result = redisUtil.get(key, returnType); if (result instanceof ResponseResult\u0026lt;?\u0026gt; r) { // 设置新的traceId r.setTraceId(TraceIdUtil.getTraceId()); } } else { // list注解, 使用自定义class解析为List result = redisUtil.getAsList(key, redisCache.listForClass()); } } else { result = joinPoint.proceed(); redisUtil.set(key, result, redisCache.expire(), redisCache.timeUnit()); } return result; } } 限制ip示例: 定义注解\n1 2 3 4 5 6 7 8 9 10 11 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) @Order(Ordered.HIGHEST_PRECEDENCE) public @interface RequestLimit { int count() default Integer.MAX_VALUE; long time() default 60000; boolean limitIp() default false; } 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 /** * @author kun.han * 如果有网关的话 做在网关 */ @Slf4j @Aspect @Component public class RequestLimitContract { @Resource RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; private final static String KEY_PREFIX = \u0026#34;requestLimit:\u0026#34;; @Before(\u0026#34;@annotation(requestLimit)\u0026#34;) public void requestLimit(final JoinPoint joinPoint, RequestLimit requestLimit) { ValueOperations\u0026lt;String, String\u0026gt; ops = redisTemplate.opsForValue(); log.info(\u0026#34;limit - count\u0026#34; + requestLimit.count() + \u0026#34; time\u0026#34; + requestLimit.time()); // 1. redis获取设置用户的count, 过期时间为time 判断是否拦截 long userId = 123123123L; String userKey = KEY_PREFIX + userId; Long count = ops.increment(userKey); count = Objects.isNull(count) ? 0 : count; if (count \u0026gt; requestLimit.count()) { throw new ServiceException(\u0026#34;限制访问\u0026#34;); } if (requestLimit.limitIp()) { // 2. ip拦截 redis获取设置ip的count, 过期时间为time 判断是否拦截 String ip = IpUtil.getIpAddress(); userKey = KEY_PREFIX + ip.replaceAll(\u0026#34;\\\\.\u0026#34;, \u0026#34;-\u0026#34;); count = ops.increment(userKey); count = Objects.isNull(count) ? 0 : count; if (count \u0026gt; requestLimit.count()) { throw new ServiceException(\u0026#34;限制访问\u0026#34;); } log.info(ip); } } } 💡 一般情况下, 这两种足够使用了.\n","permalink":"https://habyss.github.io/posts/tech/springboot_aop/","summary":"方式一: 基于表达式 例如简单日志打印: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Slf4j @Aspect @Component public class WebLogAspect { /** * xxx包及其子包下的以Contro","title":"基于springboot常用aop方式"},{"content":"UML类图关系 💡 UML 全称Unified Modeling Language, 统计建模语言.\nUML类图中有六种关系，从弱到强依次是：\n依赖关系 \u0026lt; 关联关系 \u0026lt; 聚合关系 \u0026lt; 组合关系 \u0026lt; 实现关系 = 泛化关系\n类的成员变量和方法前面的修饰符有public, private, protected, default，在UML类图中分别用 +, -, #, ~表示。\n1. 依赖关系 通用描述: 依赖关系表示某个类依赖于另外一个类\n代码表现: 某个类的方法的参数使用了另外一个类的对象\n箭头描述: 依赖关系使用带箭头的虚线表示, 箭头指向被依赖的类\n示例图样:\n2. 关联关系 通用描述: 关联关系表示一个类和另外一个类的联系, 如老师和学生\n代码表现: 某个类的成员变量是另外一个类的对象\n箭头描述: 依赖关系有单向和双向, 单向使用带箭头的实线表示, 箭头指向被关联的类, 双向使用双箭头或者没有箭头的实线表示.\n示例图样:\n3. 聚合关系 通用描述: 聚合关系是关联关系的一种, 表示的是整体与部分之间的关系, 如学校和老师, 车子和轮胎\n代码表现: 某个类的成员变量是另外一个类的对象\n箭头描述: 聚合关系使用带空心菱形的实线表示, 菱形指向整体\n示例图样:\n4. 组合关系 通用描述: 组合关系是关联关系的一种, 是一种比聚合关系更强的一种关系, 部分不能脱离整体而单独存在, 如身体和大脑\n代码表现: 某个类的成员变量是另外一个类的对象\n箭头描述: 组合关系使用带实心菱形的实线表示, 菱形指向整体\n示例图样:\n5. 实现关系 通用描述: 实现关系是接口和实现类之间的关系\n代码表现: 接口和实现类\n箭头描述: 实现关系使用带空心三角箭头的虚线表示, 箭头指向接口\n示例图样:\n6. 泛化关系 通用描述: 泛化关系是父子类之间的继承关系\n代码表现: 抽象父子与子类, 继承\n箭头描述: 泛化关系使用带空心三角箭头的实线来表示, 箭头指向父类\n示例图样:\n总结 依赖关系 \u0026lt; 关联关系 \u0026lt; 聚合关系 \u0026lt; 组合关系 \u0026lt; 实现关系 = 泛化关系 关系名称 代码表现 箭头形式 箭头指向 依赖关系 方法参数 虚线箭头 指向被依赖的类(方法参数的类) 关联关系 成员变量 实线箭头 指向被关联的类(成员变量的类) 聚合关系 成员变量 实线空心菱形 指向整体 组合关系 成员变量 实线实心菱形 指向整体 实现关系 接口与实现类 虚线空心三角 指向接口 泛化关系 抽象父类与子类 实线空心三角 指向父类 ","permalink":"https://habyss.github.io/posts/tech/uml/","summary":"UML类图关系 💡 UML 全称Unified Modeling Language, 统计建模语言. UML类图中有六种关系，从弱到强依次是： 依赖关系 \u0026lt; 关联关系 \u0026lt; 聚合关系 \u0026lt; 组合关系 \u0026lt; 实现关","title":"UML类图关系"},{"content":"@Transactional失效 整合shiro之后，UserRealm类里自动注入的service中的@Transactional注解失效\n解决方法 使用@Lazy注解\n1 2 3 @Autowired @Lazy private OperationUnitService operationUnitService; 在Realm中直接使用mapper，而不是service\n1 2 @Autowired private OperationUnitMapper operationUnitMapper; ApplicationContextRegister.getBean()方法，手动注入bean\n1 OperationUnitService operationUnitService = ApplicationContextRegister.getBean(OperationUnitService.class) 产生原因 在shiro中为了引入权限注解，配置了defaultAdvisorAutoProxyCreator和authorizationAttributeSourceAdvisor类，他们是通过AOP方式对@RequiredPermission类/方法(权限控制)进行增强.\n生成对应的代理类对象，由于shiroFilterFactoryBean实现了factoryBean接口，所以会被提前初始化，所以引发所有相关的bean提前初始化，导致他们没有被事务AOP包裹着，从而引发事务无效的问题\n1 2 3 4 5 6 7 8 9 10 11 /** * 开启Shiro的注解(如@RequiresRoles,@RequiresPermissions),需借助SpringAOP扫描使用Shiro注解的类,并在必要时进行安全逻辑验证 * 配置以下两个bean(DefaultAdvisorAutoProxyCreator(可选)和AuthorizationAttributeSourceAdvisor)即可实现此功能 */ @Bean @DependsOn({\u0026#34;lifecycleBeanPostProcessor\u0026#34;}) public DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator() { DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); advisorAutoProxyCreator.setProxyTargetClass(true); return advisorAutoProxyCreator; } 元素的 \u0026ldquo;proxy-target-class\u0026rdquo; 属性值来控制是基于接口的还是基于类的代理被创建。如果 \u0026ldquo;proxy-target-class\u0026rdquo; 属值被设置为 \u0026ldquo;true\u0026rdquo;，那么基于类的代理将起作用（这时需要CGLIB库cglib.jar在CLASSPATH中）。如果 \u0026ldquo;proxy-target-class\u0026rdquo; 属值被设置为 \u0026ldquo;false\u0026rdquo; 或者这个属性被省略，那么标准的JDK基于接口的代理将起作用。\n工具 快捷查看事务是否生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class DebugUtils { private static final boolean transactionDebugging = true; private static final boolean verboseTransactionDebugging = true; public static void showTransactionStatus(String message) { System.out.println(((transactionActive()) ? \u0026#34;[+] \u0026#34; : \u0026#34;[-] \u0026#34;) + message); } // Some guidance from: \u0026lt;http://java.dzone.com/articles/monitoring-declarative-transac?page=0,1\u0026gt; public static boolean transactionActive() { try { ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); Class tsmClass = contextClassLoader.loadClass(\u0026#34;org.springframework.transaction.support.TransactionSynchronizationManager\u0026#34;); Boolean isActive = (Boolean) tsmClass.getMethod(\u0026#34;isActualTransactionActive\u0026#34;, null).invoke(null, null); return isActive; } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (IllegalArgumentException e) { e.printStackTrace(); } catch (SecurityException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } catch (NoSuchMethodException e) { e.printStackTrace(); } // If we got here it means there was an exception throw new IllegalStateException(\u0026#34;ServerUtils.transactionActive was unable to complete properly\u0026#34;); } public static void transactionRequired(String message) { // Are we debugging transactions? if (!transactionDebugging) { // No, just return return; } // Are we doing verbose transaction debugging? if (verboseTransactionDebugging) { // Yes, show the status before we get to the possibility of throwing an exception showTransactionStatus(message); } // Is there a transaction active? if (!transactionActive()) { // No, throw an exception throw new IllegalStateException(\u0026#34;Transaction required but not active [\u0026#34; + message + \u0026#34;]\u0026#34;); } } } 在需要检测的地方\n1 DebugUtils.transactionRequired(\u0026#34;OperationUnitServiceImpl.testIn\u0026#34;); ","permalink":"https://habyss.github.io/posts/tech/transactional/","summary":"@Transactional失效 整合shiro之后，UserRealm类里自动注入的service中的@Transactional注解失效 解","title":"@Transactional失效排查"},{"content":"$ref-fastjson 问题排查 问题排查 项目返回的数据中出现$ref数据\n查询得知是fastjson的特性循环引用 fastjson支持循环引用，并且是缺省打开的。\n当序列化后的JSON传输到浏览器或者其他语言中，这些json解析器不支持循环引用，从而导致数据丢失。你可以关闭fastjson的循环引用支持。关闭引用检测，还能够提升序列化时的性能。\n全局配置关闭\n1 JSON.DEFAULT_GENERATE_FEATURE |= SerializerFeature.DisableCircularReferenceDetect.getMask(); 非全局关闭\n1 JSON.toJSONString(obj, SerializerFeature.DisableCircularReferenceDetect); 项目中配置了全局默认使用fastjson, 所以导致默认的jackson不生效. $ref-fastjson-解决方案 全局配置关闭\n非全局关闭\n删除全局默认fastjson\n","permalink":"https://habyss.github.io/posts/tech/ref-fastjson/","summary":"$ref-fastjson 问题排查 问题排查 项目返回的数据中出现$ref数据 查询得知是fastjson的特性循环引用 fastjson支持循环引用，并且是缺省打开的。 当","title":"$ref-fastjson排查"},{"content":"SpringBoot中时间戳和LocalDateTime相关的接收和转换 前言 一般情况下, 前端和后端在时间格式的传递上都走的是时间戳（方便前端自由定制） 时间格式由于java8的新增时间处理类比较好用,而且更加线程安全, 所以将项目中的时间相关改为LocalDateTime，而不是传统的Date 前置要求 mybatis需要3.4.6以上, 否则会不支持xml和javaType的转换 druid需要比较新的版本, 这里使用的是1.1.21, 否则查询会报错,结果集result set中找不到元素 正文 请求方式的情况分类\n@RequestBody中修饰LocalDateTime 其他, 比如@RequestParam和@PathVariable以及不加注解的单参数和对象参数 情况一. @RequestBody中的LocalDateTime 通过@RequestBody很明显的就是要通过JSON序列化进行处理，Spring默认的是Jackson进行处理，所以我们需要对默认的JSON处理器进行日期类型的添加(假如默认不带对应序列化器的情况下)\n此时需要用的是JsonDeserializer这个类，对应的实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * 入参 时间戳 -\u0026gt; LocalDateTime */ public class CustomDateDeserializer { public static class LocalDateTimeDeserializer extends JsonDeserializer\u0026lt;LocalDateTime\u0026gt; { @Override public LocalDateTime deserialize(JsonParser p, DeserializationContext context) throws IOException { Long timestamp = Long.valueOf(p.getText()); Instant instant = Instant.ofEpochMilli(timestamp); return LocalDateTime.ofInstant(instant, ZoneId.systemDefault()); } } } /** * @author kun.han on 2020/3/4 15:45 * 返回参数 LocalDateTime -\u0026gt; 时间戳 */ public class CustomDateSerializer { public static class LocalDateTimeSerializer extends JsonSerializer\u0026lt;LocalDateTime\u0026gt; { @Override public void serialize(LocalDateTime localDateTime, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException { jsonGenerator.writeNumber(localDateTime.toInstant(ZoneOffset.of(\u0026#34;+8\u0026#34;)).toEpochMilli()); } } } 有了这个了类，还需要添加到Spring中，Spring利用的是ObjectMapper，我们自定义一个ObjectMapper替换原本的就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Configuration public class CustomDateConfig implements WebMvcConfigurer { /** * Json序列化和反序列化转换器，用于转换Post请求体中的json以及将我们的对象序列化为返回响应的json */ @Bean public ObjectMapper objectMapper() { ObjectMapper objectMapper = new ObjectMapper(); //不显示为null的字段 objectMapper.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS); objectMapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); // 忽略不能转移的字符 objectMapper.configure(JsonParser.Feature.ALLOW_BACKSLASH_ESCAPING_ANY_CHARACTER, true); // 过滤对象的null属性. objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); //忽略transient objectMapper.configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true); objectMapper.disable(DeserializationFeature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE); //LocalDateTime系列序列化和反序列化模块，继承自jsr310，我们在这里修改了日期格式 JavaTimeModule javaTimeModule = new JavaTimeModule(); // LocalDateTime 这里只需要LocalDateTime 如果需要转其他的,相应放开注释, 并在上面两个类中适当修改 javaTimeModule.addSerializer(LocalDateTime.class, new CustomDateSerializer.LocalDateTimeSerializer()); javaTimeModule.addDeserializer(LocalDateTime.class,new CustomDateDeserializer.LocalDateTimeDeserializer()); // // LocalDate // javaTimeModule.addSerializer(LocalDate.class, new CustomDateSerializer.LocalDateSerializer()); // javaTimeModule.addDeserializer(LocalDate.class, new CustomDateDeserializer.LocalDateDeserializer()); // //Date序列化和反序列化 // javaTimeModule.addSerializer(Date.class,new CustomDateSerializer.DateSerializer()); // javaTimeModule.addDeserializer(Date.class,new CustomDateDeserializer.DateDeserializer()); objectMapper.registerModule(javaTimeModule); return objectMapper; } } 情况二. 其他 比如@RequestParam和@PathVariable以及不加注解的单参数和对象参数 方式一: Convert 可以根据自身需求进行定制，这里我通过Convert转换LocalDateTime为例，进行转换：\n1 2 3 4 5 6 7 8 9 public class CustomDateConverter { public static class LocalDateConvert implements Converter\u0026lt;String, LocalDateTime\u0026gt; { @Override public LocalDateTime convert(String timestamp) { return LocalDateTime.ofInstant(Instant.ofEpochMilli(Long.parseLong(timestamp)), ZoneId.systemDefault()); } } } 同样的需要在配置类中引用\n1 2 3 4 5 6 7 8 @Configuration public class CustomDateConfig implements WebMvcConfigurer { @Bean public Converter\u0026lt;String, LocalDateTime\u0026gt; localDateConverter() { //此处不能替换为lambda表达式 return new CustomDateConverter.LocalDateConvert(); } } 方式二: ControllerAdvice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * requestBody之外的入参 时间戳-\u0026gt;LocalDateTime * * @author hankun */ @ControllerAdvice public class LocalDateTimeAdvice { @InitBinder protected void initBinder(WebDataBinder binder) { // 这里只需要LocalDateTime 如果需要转其他的,相应添加/修改 binder.registerCustomEditor(LocalDateTime.class, new PropertyEditorSupport() { @Override public void setAsText(String timestamp) throws IllegalArgumentException { if (!StringUtils.hasText(timestamp)) { setValue(null); } else { setValue(LocalDateTime.ofInstant(Instant.ofEpochMilli(Long.parseLong(timestamp)), ZoneId.systemDefault())); } } }); // 这里只需要LocalDateTime 如果需要转其他的,相应添加/修改 binder.registerCustomEditor(LocalDate.class, new PropertyEditorSupport() { @Override public void setAsText(String timestamp) throws IllegalArgumentException { if (!StringUtils.hasText(timestamp)) { setValue(null); } else { setValue(LocalDate.ofInstant(Instant.ofEpochMilli(Long.parseLong(timestamp)), ZoneId.systemDefault())); } } }); } } 相关知识点 时间差 精确时间差:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 long start = 1584328558000L; long now = 1584400558000L; Instant startTime = Instant.ofEpochMilli(start); LocalDateTime startTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()); Instant endTime = Instant.ofEpochMilli(now); LocalDateTime entTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()); Duration duration = Duration.between(startTimeT, entTimeT); // Duration duration = Duration.between(startTime, entTime); long day = duration.toDays(); long hours = duration.toHours(); long min = duration.toMinutes(); long millis= duration.toMillis(); long nanos = duration.toNanos(); 粗略时间差, 比如今天明天算一天\n1 2 3 4 5 6 7 8 9 10 11 long start = 1584328558000L; long now = 1584400558000L; Instant startTime = Instant.ofEpochMilli(start); LocalDate startTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()).toLocalDate(); Instant endTime = Instant.ofEpochMilli(now); LocalDate entTimeT = LocalDateTime.ofInstant(startTime, ZoneId.systemDefault()).toLocalDate(); Period period = Period.between(startTimeT, entTimeT); int years = period.getYears(); int months = period.getMonths(); int days = period.getDays(); ","permalink":"https://habyss.github.io/posts/tech/springboot_localdatetime/","summary":"SpringBoot中时间戳和LocalDateTime相关的接收和转换 前言 一般情况下, 前端和后端在时间格式的传递上都走的是时间戳（方便前端","title":"SpringBoot中时间戳和LocalDateTime相关的接收和转换"},{"content":"小鹤双拼 方案一 win + R，输入 regedit，打开注册表\n找到 计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\InputMethod\\Settings\\CHS 项\n新建一个名为 UserDefinedDoublePinyinScheme0 的字符串值，值为\n1 小鹤双拼*2*^*iuvdjhcwfg^xmlnpbksqszxkrltvyovt 方案二 新建文本文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Windows Registry Editor Version 5.00 [HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\InputMethod\\Settings\\CHS] \u0026#34;EnableExtraDomainType\u0026#34;=dword:00000001 \u0026#34;EnableSmartSelfLearning\u0026#34;=dword:00000000 \u0026#34;EnableVMode\u0026#34;=dword:00000000 \u0026#34;EnableHap\u0026#34;=dword:00000000 \u0026#34;EnablePeopleName\u0026#34;=dword:00000000 \u0026#34;DoublePinyinScheme\u0026#34;=dword:0000000a \u0026#34;EnableUMode\u0026#34;=dword:00000000 \u0026#34;EnableSmartFuzzyPinyin\u0026#34;=dword:00000000 \u0026#34;UserDefinedDoublePinyinScheme0\u0026#34;=\u0026#34;小鹤双拼*2*^*iuvdjhcwfg^xmlnpbksqszxkrltvyovt\u0026#34; \u0026#34;Enable Dynamic Candidate Ranking\u0026#34;=dword:00000000 \u0026#34;Enable self-learning\u0026#34;=dword:00000000 \u0026#34;Expand Double Pinyin\u0026#34;=dword:00000000 \u0026#34;Enable Double Pinyin\u0026#34;=dword:00000001 \u0026#34;LangBar Force On\u0026#34;=dword:00000000 \u0026#34;PinyinMixEnable\u0026#34;=dword:00000000 \u0026#34;ToolBarEnabled\u0026#34;=dword:00000000 重命名.reg, 并运行\n","permalink":"https://habyss.github.io/posts/tool/%E5%B0%8F%E9%B9%A4%E5%8F%8C%E6%8B%BC/","summary":"小鹤双拼 方案一 win + R，输入 regedit，打开注册表 找到 计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\I","title":"小鹤双拼"},{"content":"Mysql-explain id id相同时, 执行顺序由上而下 id不同时, 执行顺序由大到小, 一般为子查询 select_type 查询类型, 常见的值有:\nSIMPLE: 简单查询, 不包含UNION或者子查询 PRIMARY: 查询中如果包含子查询或其他部分, 则外层的SELECT将被标记为PRIMARY SUBQUERY: 子查询中的第一个SELECT NUION: 在UNION语句中, UNION之后出现的SELECT DERIVED: 在FROM中出现的子查询 UNION RESULT: UNION查询的结果 table 当前的数据表\npartitions 查询所匹配记录的分区, 对于未分区的表, 值为NULL\ntype 查询执行的类型, 最优排行\nsystem \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; fulltext \u0026gt; ref_or_null \u0026gt; index_merge \u0026gt; unique_subquery \u0026gt; index_subquery \u0026gt; range \u0026gt; index \u0026gt; ALL\nsystem: 表中只有一行数据, 是const的一种特例 const: 表中最多只有一行匹配的记录 eq_ref: 连表查询时, 前一张表的行在当前表中只有一行与之对应(除了system与const最好的连表方式) ref: 使用普通索引作为查询条件, 查询结果可能找到多行匹配的记录 fulltext: 全文索引 ref_or_null: 使用普通索引作为查询条件 , 查询结果可能找到多行匹配的记录, 还查询了值为NULL的行 index_merge: 当查询条件使用多个索引时, index_merge表示开启了Index Merge优化 unique_subquery: eq_ref类似, 在一些使用IN的子查询中, 使用唯一索引 index_subquery: 与unique_subquery类似, 在IN子查询中, 使用了普通索引 range: 对索引列进行范围查询 index: 查询便利了整个索引树, ALL: 遍历全表, 很可能读磁盘, 速度最慢 possible_key 可能被使用的索引, 不一定被查询实际使用\nkey 查询中实际使用到的索引, 如果为NULL, 则表示为建立索引或索引失效\nkey_len 查询索引时使用的字节数, 在满足前提的需求下, 越小越好\nref 在查询索引时, 那些列或常量被用来与索引值比较\nrows 可能查询时需要遍历的行数\nfiltered 估算经过查询条件筛选出的列数的百分比\nExtra 查询时的额外信息\n当包含Using filesort或Using temporary, 需要优化\nUsing filesort: 在排序时使用了外部的索引排序, 没有使用表内的索引进行排序 Using temporary: 需要创建临时表来存储查询的结果, 常见于ORDER BY和GROUP BY Using index: 使用了索引覆盖, 查询效率非常高 Using where: 使用了WHERE子句进行条件过滤, 一般在没有使用到索引的时候出现 Impossible where: 表示where子句的结果总是false且无法查到任意行 Using join buffer(Block Nested Loop): 连表查询时, 当被驱动表没有使用索引时, 会先将驱动表读到join buffer中, 再遍历被驱动表与驱动表进行查询 Using json buffer(Batched Key Access): 与Using join buffer(Block Nested Loop)类似, 使用的是BKA算法\u0026ndash; 前提是被驱动表有索引可用 ","permalink":"https://habyss.github.io/posts/tech/mysql_explain/","summary":"Mysql-explain id id相同时, 执行顺序由上而下 id不同时, 执行顺序由大到小, 一般为子查询 select_type 查询类型, 常见的值有: SIMPLE: 简单查询, 不包含UNION或者子查询 PRIMARY: 查","title":"Mysql Explain 简解"},{"content":"Hugo+Github Pages 1. 安装Scoop win系统, 在hugo官网中也推荐了使用Scoop来进行包管理\n打开PowerShell并运行, 保证允许本地脚本的执行\n1 set-executionpolicy remotesigned -scope currentuser 执行安装命令\n1 iex (new-object net.webclient).downloadstring(\u0026#39;https://get.scoop.sh\u0026#39;) 安装成功验证\n1 scoop help 2. 安装Hugo 安装Hugo的extend版本\n1 scoop install hugo-extended 安装成功验证\n1 hugo version 3. 创建Blog hugo new site MyBlog -f yml 下载zip解压到themes, 并重命名为PaperMod 修改config.yml https://shaohanyun.top/posts/env/blog_build2/\nhttps://www.sulvblog.cn/posts/blog/build_hugo/\n","permalink":"https://habyss.github.io/posts/tech/%E6%B5%8B%E8%AF%95/","summary":"Hugo+Github Pages 1. 安装Scoop win系统, 在hugo官网中也推荐了使用Scoop来进行包管理 打开PowerShell并运行, 保证允许本地脚本的执行 1 set-executionpolicy","title":"测试"}]